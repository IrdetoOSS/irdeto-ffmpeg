diff --git a/changes.diff b/changes.diff
new file mode 100644
index 0000000..427cdd8
--- /dev/null
+++ b/changes.diff
@@ -0,0 +1,1932 @@
+diff --git a/source/libavcodec/avcodec.h b/source/libavcodec/avcodec.h
+index 39713ed..360f171 100644
+--- a/source/libavcodec/avcodec.h
++++ b/source/libavcodec/avcodec.h
+@@ -1599,6 +1599,15 @@ typedef struct AVPacket {
+ 
+     int64_t pos;                            ///< byte position in stream, -1 if unknown
+ 
++    /**
++    ****************************************************************************
++    * @author   Michael Verberne (michael.verberne@irdeto.com)
++    * @brief    Size of the header (16byte key + 1 + ber length>
++    * @date     Jul 30, 2015
++    ****************************************************************************
++    */
++    int64_t hdr_size;
++
+ #if FF_API_CONVERGENCE_DURATION
+     /**
+      * @deprecated Same as the duration field, but as int64_t. This was required
+diff --git a/source/libavcodec/avpacket.c b/source/libavcodec/avpacket.c
+index 92186892..e28cc96 100644
+--- a/source/libavcodec/avpacket.c
++++ b/source/libavcodec/avpacket.c
+@@ -35,6 +35,14 @@ void av_init_packet(AVPacket *pkt)
+     pkt->pts                  = AV_NOPTS_VALUE;
+     pkt->dts                  = AV_NOPTS_VALUE;
+     pkt->pos                  = -1;
++
++    /**
++    ****************************************************************************
++    * @author   Michael Verberne (michael.verberne@irdeto.com)
++    * @date     Jul 30, 2015
++    ****************************************************************************
++    */
++    pkt->hdr_size             = -1;
+     pkt->duration             = 0;
+ #if FF_API_CONVERGENCE_DURATION
+ FF_DISABLE_DEPRECATION_WARNINGS
+@@ -535,6 +543,14 @@ int av_packet_copy_props(AVPacket *dst, const AVPacket *src)
+     dst->pts                  = src->pts;
+     dst->dts                  = src->dts;
+     dst->pos                  = src->pos;
++
++    /**
++    ****************************************************************************
++    * @author   Michael Verberne (michael.verberne@irdeto.com)
++    * @date     Jul 30, 2015
++    ****************************************************************************
++    */
++    dst->hdr_size             = src->hdr_size;
+     dst->duration             = src->duration;
+ #if FF_API_CONVERGENCE_DURATION
+ FF_DISABLE_DEPRECATION_WARNINGS
+diff --git a/source/libavcodec/h264.c b/source/libavcodec/h264.c
+index a56f900..23ec622 100644
+--- a/source/libavcodec/h264.c
++++ b/source/libavcodec/h264.c
+@@ -692,18 +692,22 @@ static void decode_postinit(H264Context *h, int setup_finished)
+ 
+     out     = h->delayed_pic[0];
+     out_idx = 0;
+-    for (i = 1; h->delayed_pic[i] &&
+-                !h->delayed_pic[i]->f->key_frame &&
+-                !h->delayed_pic[i]->mmco_reset;
+-         i++)
+-        if (h->delayed_pic[i]->poc < out->poc) {
+-            out     = h->delayed_pic[i];
+-            out_idx = i;
+-        }
++
++    if(!h->enable_irdeto_wm) {
++        for (i = 1; h->delayed_pic[i] &&
++                    !h->delayed_pic[i]->f->key_frame &&
++                    !h->delayed_pic[i]->mmco_reset;
++             i++)
++            if (h->delayed_pic[i]->poc < out->poc) {
++                out     = h->delayed_pic[i];
++                out_idx = i;
++            }
++    }
+     if (h->avctx->has_b_frames == 0 &&
+         (h->delayed_pic[0]->f->key_frame || h->delayed_pic[0]->mmco_reset))
+         h->next_outputed_poc = INT_MIN;
+-    out_of_order = out->poc < h->next_outputed_poc;
++
++    out_of_order = h->enable_irdeto_wm ? 0 : (out->poc < h->next_outputed_poc);
+ 
+     if (out_of_order || pics > h->avctx->has_b_frames) {
+         out->reference &= ~DELAYED_PIC_REF;
+@@ -1182,6 +1186,9 @@ static int output_frame(H264Context *h, AVFrame *dst, H264Picture *srcp)
+         return ret;
+ 
+     av_dict_set(&dst->metadata, "stereo_mode", ff_h264_sei_stereo_mode(&h->sei.frame_packing), 0);
++    
++    av_frame_set_qp_table(dst, av_buffer_ref(srcp->qscale_table_buf), h->mb_stride, 0);
++    dst->mb_type = srcp->mb_type;
+ 
+     h->backup_width   = h->avctx->width;
+     h->backup_height  = h->avctx->height;
+@@ -1203,6 +1210,7 @@ static int output_frame(H264Context *h, AVFrame *dst, H264Picture *srcp)
+                       (srcp->crop_top  >> vshift) * dst->linesize[i];
+         dst->data[i] += off;
+     }
++
+     return 0;
+ }
+ 
+@@ -1310,6 +1318,19 @@ static int h264_decode_frame(AVCodecContext *avctx, void *data,
+     if (buf_index < 0)
+         return AVERROR_INVALIDDATA;
+ 
++    if (h->cur_pic_ptr == NULL)
++    	return AVERROR_INVALIDDATA;
++
++    if(h->enable_irdeto_wm) {
++        for(int i=0;i<h->mb_height;i++)
++            for(int j=0;j<h->mb_width;j++) {
++                int mbxy = i*h->mb_stride+j;
++
++                if(!(h->cbp_table[mbxy]||IS_INTRA16x16(h->cur_pic_ptr->mb_type[mbxy])))
++                    h->cur_pic_ptr->qscale_table[mbxy] = -h->cur_pic_ptr->qscale_table[mbxy]; // mark skipped blocks
++            }
++    }
++
+     if (!h->cur_pic_ptr && h->nal_unit_type == NAL_END_SEQUENCE) {
+         av_assert0(buf_index <= buf_size);
+         goto out;
+@@ -1339,6 +1360,11 @@ static int h264_decode_frame(AVCodecContext *avctx, void *data,
+             if (!h->next_output_pic->recovered)
+                 h->next_output_pic->f->flags |= AV_FRAME_FLAG_CORRUPT;
+ 
++            for(i = 0; i < h->nb_slice_ctx; i++){
++            	 if(h->slice_ctx[i].er.error_occurred)
++            		 h->next_output_pic->f->flags |= AV_FRAME_FLAG_CORRUPT;
++            }
++
+             if (!h->avctx->hwaccel &&
+                  (h->next_output_pic->field_poc[0] == INT_MAX ||
+                   h->next_output_pic->field_poc[1] == INT_MAX)
+@@ -1390,6 +1416,7 @@ static const AVOption h264_options[] = {
+     {"is_avc", "is avc", offsetof(H264Context, is_avc), AV_OPT_TYPE_BOOL, {.i64 = 0}, 0, 1, 0},
+     {"nal_length_size", "nal_length_size", offsetof(H264Context, nal_length_size), AV_OPT_TYPE_INT, {.i64 = 0}, 0, 4, 0},
+     { "enable_er", "Enable error resilience on damaged frames (unsafe)", OFFSET(enable_er), AV_OPT_TYPE_BOOL, { .i64 = -1 }, -1, 1, VD },
++	{ "enable_irdeto_wm", "Change decoder behavior to work within Irdeto WM products", OFFSET(enable_irdeto_wm), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VD },
+     { NULL },
+ };
+ 
+@@ -1445,3 +1472,47 @@ AVCodec ff_h264_vdpau_decoder = {
+     .priv_class     = &h264_vdpau_class,
+ };
+ #endif
++
++#if 0
++void SaveFrameXS(unsigned char *data, int width, int height, int stride, const char *name, int num)
++{
++	FILE *pFile;
++	char szFilename[32];
++	int  y;
++
++	sprintf(szFilename, "top_%s%d.pgm", name, num);
++	pFile = fopen(szFilename, "wb");
++	if (pFile == NULL)
++		return;
++
++	fprintf(pFile, "P5\n%d %d\n255\n", width, height);
++
++	for(y = 0; y < height/2; y++)
++		fwrite(data + y * 2 * stride, 1, width, pFile);
++
++	fclose(pFile);
++	sprintf(szFilename, "bot_%s%d.pgm", name, num);
++	pFile = fopen(szFilename, "wb");
++	if (pFile == NULL)
++		return;
++
++	fprintf(pFile, "P5\n%d %d\n255\n", width, height);
++
++	for(y = 0; y < height/2; y++)
++		fwrite(data + (y * 2 + 1) * stride, 1, width, pFile);
++
++	fclose(pFile);
++
++	sprintf(szFilename, "%s%d.pgm", name, num);
++	pFile = fopen(szFilename, "wb");
++	if (pFile == NULL)
++		return;
++
++	fprintf(pFile, "P5\n%d %d\n255\n", width, height);
++
++	for(y = 0; y < height; y++)
++		fwrite(data + y * stride, 1, width, pFile);
++
++	fclose(pFile);
++}
++#endif
+diff --git a/source/libavcodec/h264.h b/source/libavcodec/h264.h
+index 309f91d..28ce7ec 100644
+--- a/source/libavcodec/h264.h
++++ b/source/libavcodec/h264.h
+@@ -685,6 +685,8 @@ typedef struct H264Context {
+     AVBufferPool *motion_val_pool;
+     AVBufferPool *ref_index_pool;
+     int ref2frm[MAX_SLICES][2][64];     ///< reference to frame number lists, used in the loop filter, the first 2 are for -2,-1
++
++    int enable_irdeto_wm;
+ } H264Context;
+ 
+ extern const uint16_t ff_h264_mb_sizes[4];
+@@ -1001,4 +1003,8 @@ void ff_h264_free_tables(H264Context *h);
+ 
+ void ff_h264_set_erpic(ERPicture *dst, H264Picture *src);
+ 
++#if 0
++void SaveFrameXS(unsigned char *data, int width, int height, int stride, const char *name, int num);
++#endif
++
+ #endif /* AVCODEC_H264_H */
+diff --git a/source/libavcodec/h264_mb_template.c b/source/libavcodec/h264_mb_template.c
+index d5ea26a..2765347 100644
+--- a/source/libavcodec/h264_mb_template.c
++++ b/source/libavcodec/h264_mb_template.c
+@@ -187,9 +187,42 @@ static av_noinline void FUNC(hl_decode_mb)(const H264Context *h, H264SliceContex
+             }
+         }
+ 
++        /*
++         * copy predicted mb to plane 3
++         */
++        if(h->enable_irdeto_wm){
++			uint8_t *src = h->cur_pic.f->data[0] + ((mb_x << PIXEL_SHIFT) + mb_y * h->mb_stride) * 16;
++			uint8_t *dst = h->cur_pic.f->data[3] + ((mb_x << PIXEL_SHIFT) + mb_y * h->mb_stride) * 16;
++			int inc = h->mb_stride;
++			if (( (FRAME_MBAFF(h) && MB_MBAFF(sl)) || (!FRAME_MBAFF(h) && MB_FIELD(sl)))) {
++				inc *= 2;
++				if  (mb_y & 0x1) {
++					src -= 15 * h->mb_stride;
++					dst -= 15 * h->mb_stride;
++				}
++			}
++			for (i = 0; i < 16; i++) {
++				memcpy(dst, src, 16);
++				src += inc;
++				dst += inc;
++			}
++        }
++
+         hl_decode_mb_idct_luma(h, sl, mb_type, SIMPLE, transform_bypass,
+                                PIXEL_SHIFT, block_offset, linesize, dest_y, 0);
+ 
++#if 0
++        {
++		static int picno = 0;
++		if (h->mb_x >= h->mb_width -1 && h->mb_y >= h->mb_height -1) {
++			fprintf(stderr, "\npicno:%d FRAME_MBAFF(h):%d MB_MBAFF(h):%d  MB_FIELD(h):%d", picno, FRAME_MBAFF(h), MB_MBAFF(h), MB_FIELD(h));
++			SaveFrameXS((unsigned char *) h->cur_pic.f.data[3], h->width, h->height, h->linesize, "libav_pred_", picno);
++			SaveFrameXS((unsigned char *) h->cur_pic.f.data[0], h->width, h->height, h->linesize, "libav_dec_", picno);
++			picno++;
++			fprintf(stderr, "\n************");
++		}
++	}
++#endif
+         if ((SIMPLE || !CONFIG_GRAY || !(h->flags & AV_CODEC_FLAG_GRAY)) &&
+             (sl->cbp & 0x30)) {
+             uint8_t *dest[2] = { dest_cb, dest_cr };
+diff --git a/source/libavcodec/hevc.c b/source/libavcodec/hevc.c
+index cb1263c..e2dbd9b 100644
+--- a/source/libavcodec/hevc.c
++++ b/source/libavcodec/hevc.c
+@@ -43,11 +43,235 @@
+ 
+ const uint8_t ff_hevc_pel_weight[65] = { [2] = 0, [4] = 1, [6] = 2, [8] = 3, [12] = 4, [16] = 5, [24] = 6, [32] = 7, [48] = 8, [64] = 9 };
+ 
++
++#ifdef IRDETO
++static void hev_copy_vps(HEVCContext *s)
++{
++	uint32_t *data = ((HEVCIrdetoExport*)s->ref->irdeto_export)->vps;
++	int i = 0;
++
++	memset(data, 0, sizeof((HEVCIrdetoExport*)s->ref->irdeto_export)->vps);
++
++	data[i++] = s->ps.sps->vps_id;
++	data[i++] = s->ps.vps->vps_max_sub_layers;
++	data[i++] = s->ps.vps->vps_temporal_id_nesting_flag;
++	data[i++] = s->ps.vps->ptl.general_ptl.profile_space;
++	data[i++] = s->ps.vps->ptl.general_ptl.tier_flag;
++	data[i++] = s->ps.vps->ptl.general_ptl.profile_idc;
++	data[i++] = s->ps.vps->ptl.general_ptl.level_idc;
++
++	for (; i < 64; i++)
++		data[i] = 0;
++}
++
++static void hev_copy_sps(HEVCContext *s)
++{
++	uint32_t *data = ((HEVCIrdetoExport*)s->ref->irdeto_export)->sps;
++	int i = 0;
++
++	memset(data, 0, sizeof((HEVCIrdetoExport*)s->ref->irdeto_export)->sps);
++
++	data[i++] = s->ps.sps->vps_id;;
++	data[i++] = s->ps.sps->max_sub_layers;
++	data[i++] = s->ps.sps->sps_temporal_id_nesting_flag;
++	data[i++] = s->ps.pps->sps_id;
++	data[i++] = s->ps.sps->chroma_format_idc;
++	data[i++] = s->ps.sps->width; // !mv ??
++	data[i++] = s->ps.sps->height; // !mv ??;
++	data[i++] = s->ps.sps->bit_depth;
++	data[i++] = s->ps.sps->bit_depth_chroma;
++	data[i++] = s->ps.sps->log2_max_poc_lsb;
++	data[i++] = s->ps.sps->log2_min_cb_size;
++	data[i++] = s->ps.sps->log2_diff_max_min_coding_block_size;
++	data[i++] = s->ps.sps->log2_min_tb_size;
++	data[i++] = s->ps.sps->log2_max_trafo_size;
++	data[i++] = s->ps.sps->max_transform_hierarchy_depth_inter;
++	data[i++] = s->ps.sps->max_transform_hierarchy_depth_intra;
++	data[i++] = s->ps.sps->scaling_list_enable_flag;
++	data[i++] = s->ps.sps->amp_enabled_flag;
++	data[i++] = s->ps.sps->sao_enabled;
++	data[i++] = s->ps.sps->pcm_enabled_flag;
++	data[i++] = s->ps.sps->sps_temporal_mvp_enabled_flag;
++	data[i++] = s->ps.sps->sps_strong_intra_smoothing_enable_flag;
++	data[i++] = s->ps.sps->vui_present;
++	data[i++] = s->ps.sps->nb_st_rps;
++
++	for (; i < 64; i++)
++		data[i] = 0;
++}
++
++
++static void hev_copy_pps(HEVCContext *s)
++{
++	uint32_t *data = ((HEVCIrdetoExport*)s->ref->irdeto_export)->pps;
++	int i = 0;
++
++	memset(data, 0, sizeof((HEVCIrdetoExport*)s->ref->irdeto_export)->pps);
++
++	data[i++] = s->ps.pps->diff_cu_qp_delta_depth;
++	data[i++] = s->ps.pps->cb_qp_offset;
++	data[i++] = s->ps.pps->cr_qp_offset;
++	data[i++] = s->ps.pps->weighted_pred_flag;
++	data[i++] = s->ps.pps->weighted_bipred_flag;
++	data[i++] = s->ps.pps->cu_qp_delta_enabled_flag;
++	data[i++] = s->ps.pps->constrained_intra_pred_flag;
++	data[i++] = s->ps.pps->transquant_bypass_enable_flag;
++	data[i++] = s->ps.pps->transform_skip_enabled_flag;
++	data[i++] = s->ps.pps->entropy_coding_sync_enabled_flag;
++	data[i++] = s->ps.pps->sign_data_hiding_flag;
++	data[i++] = s->ps.pps->deblocking_filter_control_present_flag;
++	if (!s->ps.pps->deblocking_filter_control_present_flag) {
++		data[i++] = 0;
++	}
++	else {
++		data[i++] = s->ps.pps->deblocking_filter_override_enabled_flag;
++	}
++	data[i++] = s->ps.pps->disable_dbf;
++	data[i++] = s->ps.pps->beta_offset/2;
++	data[i++] = s->ps.pps->tc_offset/2;
++	data[i++] = s->ps.pps->lists_modification_present_flag;
++	data[i++] = s->ps.pps->cabac_init_present_flag;
++
++	for (; i < 64; i++)
++		data[i] = 0;
++}
++
++static void hev_copy_slc(HEVCContext *s)
++{
++	uint32_t *data = ((HEVCIrdetoExport*)s->ref->irdeto_export)->slc;
++	uint32_t i = 0, j, MAX_NUM_REF = 16, k;
++
++	memset(data, 0, sizeof((HEVCIrdetoExport*)s->ref->irdeto_export)->slc);
++
++	// margins, must be valid when exporting ref yuv pics
++	data[i++] = 0; // ?? MarginX
++	data[i++] = 0; // ?? marginY
++
++	// rps
++	// handle.write((const char *)&m_numberOfPictures, SIZE_OF_INT32);			// write it to 32bit int
++	if (s->sh.short_term_rps != NULL) {
++		data[i++] = s->sh.short_term_rps->num_delta_pocs;
++
++		//handle.write((const char *)&m_numberOfNegativePictures, SIZE_OF_INT32);
++		data[i++] = s->sh.short_term_rps->num_negative_pics;
++
++		// handle.write((const char *)&m_numberOfPositivePictures, SIZE_OF_INT32);
++		data[i++] = s->sh.short_term_rps->num_delta_pocs - s->sh.short_term_rps->num_negative_pics; // correct??
++
++		//handle.write((const char *)m_POC, SIZE_OF_INT32*MAX_NUM_REF_PICS);
++		for (j = 0; j <  MAX_NUM_REF; j++) {
++			if (j < s->sh.slice_rps.num_delta_pocs || j >= s->sh.long_term_rps.nb_refs + s->sh.slice_rps.num_delta_pocs) {
++				data[i++] = 0;
++			}
++			else {
++				data[i++] = s->sh.long_term_rps.poc [j - s->sh.slice_rps.num_delta_pocs];
++			}
++		}
++
++		//handle.write((const char *)m_deltaPOC, SIZE_OF_INT32*MAX_NUM_REF_PICS);
++		for (j = 0; j <  MAX_NUM_REF; j++) {
++			if (j < s->sh.short_term_rps->num_delta_pocs) {
++				data[i++] = s->sh.short_term_rps->delta_poc[j];
++			}
++			else {
++				data[i++] = 0;
++			}
++		}
++
++		//handle.write((const char *)m_used, SIZE_OF_CHAR*MAX_NUM_REF_PICS);
++		for (j = 0; j <  MAX_NUM_REF; j++) {
++			if (j < s->sh.short_term_rps->num_delta_pocs) {
++				data[i++] = s->sh.short_term_rps->used[j];
++			}
++			else if (j < s->sh.long_term_rps.nb_refs + s->sh.slice_rps.num_delta_pocs) {
++				data[i++] = s->sh.long_term_rps.used[j - s->sh.slice_rps.num_delta_pocs];
++			}
++			else {
++				data[i++] = 0;
++			}
++		}
++	}
++	else {
++		i+= 51;
++	}
++
++	data[i++] = s->nal_unit_type;
++	data[i++] = s->sh.slice_type;
++	data[i++] = s->sh.slice_qp;
++	data[i++] = s->poc;//??
++	data[i++] = 0; //s->??m_lastIDR SCSA does not write correct value.
++	data[i++] = 0; //m_bCheckLDC s->?? low delay check , tdectop, ln 632
++	data[i++] = s->sh.slice_loop_filter_across_slices_enabled_flag;
++	data[i++] = s->sh.collocated_list;
++	data[i++] = s->sh.collocated_ref_idx;
++	data[i++] = s->sh.nb_refs[L0]; // num_ref_idx_l0_active_minus1 + 1 or num_ref_idx_l0_default_active +1
++	data[i++] = s->sh.nb_refs[L1]; // num_ref_idx_l1_active_minus1 + 1 or num_ref_idx_l1_default_active +1
++
++	// (char *)m_refPOCList, SIZE_OF_INT32*(2 * (MAX_NUM_REF + 1))
++	for (k = 0; k < 2; k++) {
++		for (j = 0; j < MAX_NUM_REF; j++) {
++			if (s->ref->refPicList != NULL && s->ref->refPicList[k].ref[j] != NULL) {
++				data[i++] = s->ref->refPicList[k].ref[j]->poc;// ?? hevc_refs, 323
++			}
++			else {
++				data[i++] = 0;
++			}
++		}
++		data[i++] = 0; // ?? there is a maximum of 16 references, why MAX_NUM_REF + 1 ?
++	}
++
++	data[i++] = s->sh.max_num_merge_cand;
++	data[i++] = s->ps.sps->ctb_size; //?? m_endCUAddr see TDecCAVLC ln 1002
++	data[i++] = s->sh.deblocking_filter_override_flag;
++	data[i++] = s->sh.disable_deblocking_filter_flag;
++	data[i++] = s->sh.beta_offset/2;
++	data[i++] = s->sh.tc_offset/2;
++
++	// list modifications
++	int nb_refs = ff_hevc_frame_nb_refs(s);
++	data[i++] = s->ps.pps->lists_modification_present_flag;
++	if (s->ps.pps->lists_modification_present_flag && nb_refs > 1) 	{
++		if (s->sh.rpl_modification_flag[0]) 	{
++			data[i++] = av_ceil_log2(nb_refs);
++			for (j = 0; j < s->sh.nb_refs[L0]; j++) {
++				data[i++] = s->sh.list_entry_lx[0][j];
++			}
++		}
++		if (s->sh.rpl_modification_flag[1]) 	{
++			data[i++] = av_ceil_log2(nb_refs);
++			for (j = 0; j < s->sh.nb_refs[L1]; j++)	{
++				data[i++] = s->sh.list_entry_lx[1][j];
++			}
++		}
++	}
++
++	for (; i < 256; i++)
++		data[i] = 0;
++}
++
++
+ /**
+  * NOTE: Each function hls_foo correspond to the function foo in the
+  * specification (HLS stands for High Level Syntax).
+  */
+ 
++static AVFrame *hevc_av_frame_alloc(void)
++{
++	AVFrame *frame;
++
++	if ((frame = av_frame_alloc()) == NULL) {
++		return NULL;
++	}
++	return frame;
++}
++
++static void hevc_av_frame_free(AVFrame **frame)
++{
++	av_frame_free(frame);
++}
++
++#endif
++
+ /**
+  * Section 5.7
+  */
+@@ -705,6 +929,10 @@ static int hls_slice_header(HEVCContext *s)
+             if (s->ps.pps->deblocking_filter_override_enabled_flag)
+                 deblocking_filter_override_flag = get_bits1(gb);
+ 
++#ifdef IRDETO
++            sh->deblocking_filter_override_flag = deblocking_filter_override_flag; // !mv
++#endif
++
+             if (deblocking_filter_override_flag) {
+                 sh->disable_deblocking_filter_flag = get_bits1(gb);
+                 if (!sh->disable_deblocking_filter_flag) {
+@@ -2970,6 +3198,8 @@ static int verify_md5(HEVCContext *s, AVFrame *frame)
+     return 0;
+ }
+ 
++
++
+ static int hevc_decode_frame(AVCodecContext *avctx, void *data, int *got_output,
+                              AVPacket *avpkt)
+ {
+@@ -3013,6 +3243,12 @@ static int hevc_decode_frame(AVCodecContext *avctx, void *data, int *got_output,
+     if (s->is_decoded) {
+         av_log(avctx, AV_LOG_DEBUG, "Decoded frame with POC %d.\n", s->poc);
+         s->is_decoded = 0;
++#ifdef IRDETO
++    	hev_copy_vps(s);
++    	hev_copy_sps(s);
++    	hev_copy_pps(s);
++    	hev_copy_slc(s);
++#endif
+     }
+ 
+     if (s->output_frame->buf[0]) {
+@@ -3079,11 +3315,20 @@ static av_cold int hevc_decode_free(AVCodecContext *avctx)
+         av_freep(&s->sao_pixel_buffer_h[i]);
+         av_freep(&s->sao_pixel_buffer_v[i]);
+     }
++#ifdef IRDETO
++    hevc_av_frame_free(&s->output_frame);
++#else
+     av_frame_free(&s->output_frame);
++#endif
+ 
+     for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {
+         ff_hevc_unref_frame(s, &s->DPB[i], ~0);
++#ifdef IRDETO
++        av_free(s->DPB[i].irdeto_export);
++        hevc_av_frame_free(&s->DPB[i].frame);
++#else
+         av_frame_free(&s->DPB[i].frame);
++#endif
+     }
+ 
+     for (i = 0; i < FF_ARRAY_ELEMS(s->ps.vps_list); i++)
+@@ -3133,15 +3378,26 @@ static av_cold int hevc_init_context(AVCodecContext *avctx)
+     if (!s->cabac_state)
+         goto fail;
+ 
++#ifdef IRDETO
++    s->output_frame = hevc_av_frame_alloc();
++#else
+     s->output_frame = av_frame_alloc();
++#endif
+     if (!s->output_frame)
+         goto fail;
+ 
+     for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {
++#ifdef IRDETO
++        s->DPB[i].frame = hevc_av_frame_alloc();
++#else
+         s->DPB[i].frame = av_frame_alloc();
++#endif
+         if (!s->DPB[i].frame)
+             goto fail;
+         s->DPB[i].tf.f = s->DPB[i].frame;
++#ifdef IRDETO
++        s->DPB[i].irdeto_export = av_mallocz(sizeof(HEVCIrdetoExport));
++#endif
+     }
+ 
+     s->max_ra = INT_MAX;
+diff --git a/source/libavcodec/hevc.h b/source/libavcodec/hevc.h
+index be91010..5192584 100644
+--- a/source/libavcodec/hevc.h
++++ b/source/libavcodec/hevc.h
+@@ -43,6 +43,8 @@
+ #define MAX_NB_THREADS 16
+ #define SHIFT_CTB_WPP 2
+ 
++#define IRDETO
++
+ /**
+  * 7.4.2.1
+  */
+@@ -88,6 +90,19 @@
+                    (s)->nal_unit_type == NAL_BLA_N_LP)
+ #define IS_IRAP(s) ((s)->nal_unit_type >= 16 && (s)->nal_unit_type <= 23)
+ 
++#ifdef IRDETO
++/**
++ * data exports, goes to opaque.
++ */
++typedef struct  HEVCIrdetoExport {
++	uint32_t vps[64];
++	uint32_t sps[64];
++	uint32_t pps[64];
++	uint32_t slc[256]; 	// data file containing margins and slice header data
++} HEVCIrdetoExport;
++
++#endif
++
+ /**
+  * Table 7-3: NAL unit type codes
+  */
+@@ -398,6 +413,9 @@ typedef struct ScalingList {
+ 
+ typedef struct HEVCSPS {
+     unsigned vps_id;
++#ifdef IRDETO
++    uint8_t sps_temporal_id_nesting_flag;
++#endif
+     int chroma_format_idc;
+     uint8_t separate_colour_plane_flag;
+ 
+@@ -408,6 +426,9 @@ typedef struct HEVCSPS {
+     HEVCWindow pic_conf_win;
+ 
+     int bit_depth;
++#ifdef IRDETO
++    int bit_depth_chroma;
++#endif
+     int pixel_shift;
+     enum AVPixelFormat pix_fmt;
+ 
+@@ -421,6 +442,9 @@ typedef struct HEVCSPS {
+         int max_latency_increase;
+     } temporal_layer[MAX_SUB_LAYERS];
+ 
++#ifdef IRDETO
++    uint8_t vui_present;
++#endif
+     VUI vui;
+     PTL ptl;
+ 
+@@ -451,6 +475,9 @@ typedef struct HEVCSPS {
+     unsigned int log2_min_cb_size;
+     unsigned int log2_diff_max_min_coding_block_size;
+     unsigned int log2_min_tb_size;
++#ifdef IRDETO
++    unsigned int log2_diff_max_min_transform_block_size;
++#endif
+     unsigned int log2_max_trafo_size;
+     unsigned int log2_ctb_size;
+     unsigned int log2_min_pu_size;
+@@ -645,6 +672,10 @@ typedef struct SliceHeader {
+     int16_t chroma_offset_l1[16][2];
+ 
+     int slice_ctb_addr_rs;
++
++#ifdef IRDETO
++    uint8_t deblocking_filter_override_flag; //!mv
++#endif
+ } SliceHeader;
+ 
+ typedef struct CodingUnit {
+@@ -745,6 +776,10 @@ typedef struct HEVCFrame {
+      * A combination of HEVC_FRAME_FLAG_*
+      */
+     uint8_t flags;
++
++#ifdef IRDETO
++    HEVCIrdetoExport *irdeto_export;
++#endif
+ } HEVCFrame;
+ 
+ typedef struct HEVCLocalContext {
+@@ -790,6 +825,107 @@ typedef struct HEVCLocalContext {
+     int boundary_flags;
+ } HEVCLocalContext;
+ 
++
++#ifdef IRDETO
++/*
++JRen : Store header info from original stream
++*/
++typedef struct
++{
++	uint32_t vps_id;
++	uint32_t maxTempSubLayers;
++	uint32_t temporalIdNestingFlag;
++	uint32_t profileSpace;
++	uint32_t tier_flag;
++	uint32_t profile_idc;
++	uint32_t level_idc;
++} HEVCExportVps;
++
++typedef struct
++{
++	int32_t vps_id;
++	uint32_t bTemporalIdNestingFlag;
++	uint32_t sps_id;
++	uint32_t bitDepthY;
++	uint32_t bitDepthC;
++	uint32_t scalingListEnabledFlag;
++	uint32_t bUsePCM;
++	uint32_t bVuiPresent;
++
++	uint32_t chromaFormatIdc;
++	uint32_t picWidthInLumaSamples;
++	uint32_t picHeightInLumaSamples;
++
++	uint32_t numCuInWidth; 			// !mv not used
++	uint32_t numCuInHeight; 		// !mv not used
++	uint32_t numCUsInFrame; 		// !mv not used
++	uint32_t numPartitions; 		// !mv not used
++	uint32_t numPartInCUSize; 		// !mv not used
++
++	uint32_t numBitsForPoc;
++	uint32_t log2MinCodingBlockSize;
++	uint32_t log2DiffMaxMinCodingBlockSize;
++
++	uint32_t quadtreeTULog2MaxSize;
++	uint32_t quadtreeTULog2MinSize;
++
++	uint32_t quadtreeTUMaxDepthInter;
++	uint32_t quadtreeTUMaxDepthIntra;
++
++	uint32_t bUseSAO;
++	uint32_t bUseAMP;
++	uint32_t maxAMPDepth; 			// !mv not used
++
++	uint32_t maxTempSubLayers;   	// max number of Temporal Sub layers
++
++	uint32_t maxDecPicBuffering; 	// !mv not used these are dups of VPS values
++	uint32_t maxLatencyIncrease; 	// !mv not used
++	uint32_t numReorderPics; 		// !mv not used
++
++	uint32_t bUseStrongIntraSmoothing;
++	uint32_t bTemporalMVPEnabled;
++
++	uint32_t num_short_term_ref_pic_sets;
++} HEVCExportSps;;
++
++typedef struct
++{
++	uint32_t maxCuDQPDepth;
++
++	int      chromaQpOffset[2];      // use param
++
++	uint32_t     bUseWeightPred;         // use param
++	uint32_t     bUseWeightedBiPred;     // use param
++	uint32_t     bUseDQP;
++	uint32_t     bConstrainedIntraPred;  // use param
++
++	uint32_t     bTransquantBypassEnabled;  // Indicates presence of cu_transquant_bypass_flag in CUs.
++	uint32_t     bTransformSkipEnabled;     // use param
++	uint32_t     bEntropyCodingSyncEnabled; // use param
++	uint32_t     bSignHideEnabled;          // use param
++
++	uint32_t     bDeblockingFilterControlPresent;
++	uint32_t     bDeblockingFilterOverrideEnabledFlag;			// JRen : new added
++	uint32_t     bPicDisableDeblockingFilter;
++	int      deblockingFilterBetaOffsetDiv2;
++	int      deblockingFilterTcOffsetDiv2;
++
++	uint32_t	bListsModificationPresentFlag;					// JRen : new added
++	uint32_t	cabac_init_present_flag;						// JRen: SCR24594
++
++	// James : tile structure
++	uint32_t	bTilesEnabledFlag;		// !mv not used
++	uint32_t	bUniformSpacingFlag; // !mv not used
++	int		m_numTileColumnsMinus1; // !mv not used
++	int		m_numTileRowsMinus1; // !mv not used
++	int *	m_tileColumnWidth; // !mv not used
++	int *	m_tileRowHeight; // !mv not used
++	uint32_t	bLoopFilterAcrossTilesEnabledFlag; // !mv not used
++} HEVCExportPps;
++
++#endif
++
++
+ typedef struct HEVCContext {
+     const AVClass *c;  // needed by private avoptions
+     AVCodecContext *avctx;
+@@ -812,6 +948,9 @@ typedef struct HEVCContext {
+ 
+     AVFrame *frame;
+     AVFrame *output_frame;
++#ifdef IRDETO
++  //  HEVCIrdetoExport *irdeto_export;
++#endif
+     uint8_t *sao_pixel_buffer_h[3];
+     uint8_t *sao_pixel_buffer_v[3];
+ 
+@@ -832,6 +971,9 @@ typedef struct HEVCContext {
+     HEVCFrame DPB[32];
+     int poc;
+     int pocTid0;
++#ifdef IRDETO
++    int poc_lastIdr; // !mv
++#endif
+     int slice_idx; ///< number of the slice being currently decoded
+     int eos;       ///< current packet contains an EOS/EOB NAL
+     int last_eos;  ///< last packet contains an EOS/EOB NAL
+@@ -924,6 +1066,8 @@ typedef struct HEVCContext {
+ 
+ } HEVCContext;
+ 
++
++
+ int ff_hevc_decode_short_term_rps(GetBitContext *gb, AVCodecContext *avctx,
+                                   ShortTermRPS *rps, const HEVCSPS *sps, int is_slice_header);
+ 
+diff --git a/source/libavcodec/hevc_ps.c b/source/libavcodec/hevc_ps.c
+index 83f2ec2..b068f79 100644
+--- a/source/libavcodec/hevc_ps.c
++++ b/source/libavcodec/hevc_ps.c
+@@ -840,7 +840,11 @@ int ff_hevc_parse_sps(HEVCSPS *sps, GetBitContext *gb, unsigned int *sps_id,
+         return AVERROR_INVALIDDATA;
+     }
+ 
++#ifdef IRDETO
++    sps->sps_temporal_id_nesting_flag = get_bits1(gb);
++#else
+     skip_bits1(gb); // temporal_id_nesting_flag
++#endif
+ 
+     if ((ret = parse_ptl(gb, avctx, &sps->ptl, sps->max_sub_layers)) < 0)
+         return ret;
+@@ -896,6 +900,10 @@ int ff_hevc_parse_sps(HEVCSPS *sps, GetBitContext *gb, unsigned int *sps_id,
+ 
+     sps->bit_depth   = get_ue_golomb_long(gb) + 8;
+     bit_depth_chroma = get_ue_golomb_long(gb) + 8;
++
++#ifdef IRDETO
++    sps->bit_depth_chroma = bit_depth_chroma;
++#endif
+     if (sps->chroma_format_idc && bit_depth_chroma != sps->bit_depth) {
+         av_log(avctx, AV_LOG_ERROR,
+                "Luma bit depth (%d) is different from chroma bit depth (%d), "
+@@ -1036,6 +1044,11 @@ int ff_hevc_parse_sps(HEVCSPS *sps, GetBitContext *gb, unsigned int *sps_id,
+     sps->sps_strong_intra_smoothing_enable_flag = get_bits1(gb);
+     sps->vui.sar = (AVRational){0, 1};
+     vui_present = get_bits1(gb);
++
++#ifdef IRDETO
++    sps->vui_present = vui_present;
++#endif
++
+     if (vui_present)
+         decode_vui(gb, avctx, apply_defdispwin, sps);
+ 
+diff --git a/source/libavcodec/hevc_refs.c b/source/libavcodec/hevc_refs.c
+index 611ad45..157962c 100644
+--- a/source/libavcodec/hevc_refs.c
++++ b/source/libavcodec/hevc_refs.c
+@@ -209,6 +209,10 @@ int ff_hevc_output_frame(HEVCContext *s, AVFrame *out, int flush)
+             int pixel_shift = !!(desc->comp[0].depth > 8);
+ 
+             ret = av_frame_ref(out, src);
++#ifdef IRDETO
++            dst->opaque = frame->irdeto_export; //!mv not necessary, see copy_props() in av_frame_ref()
++#endif
++
+             if (frame->flags & HEVC_FRAME_FLAG_BUMPING)
+                 ff_hevc_unref_frame(s, frame, HEVC_FRAME_FLAG_OUTPUT | HEVC_FRAME_FLAG_BUMPING);
+             else
+diff --git a/source/libavfilter/Makefile b/source/libavfilter/Makefile
+index 65a831e..32afe46 100644
+--- a/source/libavfilter/Makefile
++++ b/source/libavfilter/Makefile
+@@ -126,6 +126,7 @@ OBJS-$(CONFIG_BENCH_FILTER)                  += f_bench.o
+ OBJS-$(CONFIG_BLACKDETECT_FILTER)            += vf_blackdetect.o
+ 
+ # video filters
++OBJS-$(CONFIG_RGBCNT_FILTER) 				 += vf_rgb_cnt.o
+ OBJS-$(CONFIG_BLACKFRAME_FILTER)             += vf_blackframe.o
+ OBJS-$(CONFIG_BLEND_FILTER)                  += vf_blend.o dualinput.o framesync.o
+ OBJS-$(CONFIG_BOXBLUR_FILTER)                += vf_boxblur.o
+diff --git a/source/libavfilter/allfilters.c b/source/libavfilter/allfilters.c
+index d0d491e..3505b4b 100644
+--- a/source/libavfilter/allfilters.c
++++ b/source/libavfilter/allfilters.c
+@@ -135,6 +135,7 @@ void avfilter_register_all(void)
+ 
+     REGISTER_FILTER(ANULLSINK,      anullsink,      asink);
+ 
++    REGISTER_FILTER(RGBCNT,         rgbcnt,         vf);
+     REGISTER_FILTER(ALPHAEXTRACT,   alphaextract,   vf);
+     REGISTER_FILTER(ALPHAMERGE,     alphamerge,     vf);
+     REGISTER_FILTER(ATADENOISE,     atadenoise,     vf);
+diff --git a/source/libavfilter/vf_rgb_cnt.c b/source/libavfilter/vf_rgb_cnt.c
+new file mode 100644
+index 0000000..c211a42
+--- /dev/null
++++ b/source/libavfilter/vf_rgb_cnt.c
+@@ -0,0 +1,460 @@
++/*
++* Copyright (c) 2013-2016 Irdeto B.V.
++*
++* This file is part of FFmpeg.
++*
++* FFmpeg is free software; you can redistribute it and/or
++* modify it under the terms of the GNU Lesser General Public
++* License as published by the Free Software Foundation; either
++* version 2.1 of the License, or (at your option) any later version.
++*
++* FFmpeg is distributed in the hope that it will be useful,
++* but WITHOUT ANY WARRANTY; without even the implied warranty of
++* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
++* Lesser General Public License for more details.
++*
++* You should have received a copy of the GNU Lesser General Public
++* License along with FFmpeg; if not, write to the Free Software
++* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
++*/
++
++// Global system includes
++#include <unistd.h>
++#include <dlfcn.h>
++#include <stdio.h>
++#include <inttypes.h>
++
++// FFmpeg libavutil includes
++#include "libavutil/pixdesc.h"
++#include "libavutil/colorspace.h"
++#include "libavutil/imgutils.h"
++#include "libavutil/opt.h"
++
++// FFmpeg libswscale includes
++#include "libswscale/swscale.h"
++
++// FFmpeg libavfilter includes
++#include "config.h"
++#include "avfilter.h"
++#include "formats.h"
++#include "internal.h"
++#include "video.h"
++
++/**
++********************************************************************************
++* @enum         VF_STATE
++* @brief        Video filter states representation
++********************************************************************************
++*/
++typedef enum
++{
++    VF_STATE_UNINITIALIZED  = 0,    ///< Video filter uninitialized
++    VF_STATE_INITIALIZED    = 1     ///< Video filter initialized
++} VF_STATE;
++
++/**
++********************************************************************************
++* @enum         COLOR
++* @brief        RGB color space representation
++********************************************************************************
++*/
++typedef enum
++{
++    RED      = 0,    ///< R
++    GREEN    = 1,    ///< G
++    BLUE     = 2,    ///< B
++    NONE     = 3     ///< Uninit value
++} COLOR;
++
++static const char* color_name[4] = 
++{
++    "Red",
++    "Green",
++    "Blue",
++    "None"
++};
++
++/**
++********************************************************************************
++* @enum         IR_RGBCNT_STATUS
++* @brief        OTT watermarking library error codes
++********************************************************************************
++*/
++typedef enum
++{
++    IR_RGBCNT_STATUS_OK      = 0,    ///< OK
++    IR_RGBCNT_STATUS_NI      = 1,    ///< Not implemented
++    IR_RGBCNT_STATUS_BADARG  = 2,    ///< Bad arguments passed
++    IR_RGBCNT_STATUS_LIF     = 3,    ///< Failed to initialize WM library
++    IR_RGBCNT_STATUS_OIF     = 4,    ///< Failed to set operator ID
++    IR_RGBCNT_STATUS_FWS     = 5,    ///< TBD
++    IR_RGBCNT_STATUS_FPF     = 6,    ///< Failed to set frame properties
++    IR_RGBCNT_STATUS_SKIP    = 7,
++    IR_RGBCNT_STATUS_FAIL    = -1
++
++} IR_RGBCNT_STATUS;
++
++typedef struct ir_rgb_context
++{
++    int            width;
++    int            height;
++    int            linesize;
++    int            detph;
++    float          fps;
++
++    uint8_t*       rgb_data;
++    size_t         rgb_size;
++    AVFrame*       pFrameRGB;
++
++    VF_STATE       state;
++    COLOR          color;
++    COLOR          prev_color;
++    int            red_cnt;
++    int            green_cnt;
++    int            blue_cnt;
++} RgbcntContext;
++
++/**
++********************************************************************************
++* @brief    Irdeto FFmpeg rgb counter initialization routine
++* @param    [in] ctx    Pointer to the Filter context
++* @return   0 on success, AVERROR - otherwise
++********************************************************************************
++*/
++static av_cold int vf_rgbcnt_init(AVFilterContext* const ctx)
++{
++    int sys = 0;
++    struct ir_rgb_context* context = ctx->priv;
++
++    context->state = VF_STATE_UNINITIALIZED;
++
++    return AVERROR(sys);
++}
++
++/**
++********************************************************************************
++* @brief        Does post initialization of the rgb counter when all
++*               stream characteristics known
++* @param        [in] inlink     Pointer to the input stream information
++* @param        [in] frame      Pointer to the FFmpeg frame
++* @return       IR_OTTWM_STATUS_OK on success, IR_OTTWM_STATUS_FAIL - otherwise
++********************************************************************************
++*/
++static IR_RGBCNT_STATUS vf_rgbcnt_postinit(AVFilterLink* const inlink,
++    AVFrame* const frame)
++{
++    AVFilterContext* filter = (AVFilterContext*) inlink->dst;
++    struct ir_rgb_context* context = (struct ir_rgb_context*) filter->priv;
++    IR_RGBCNT_STATUS result = IR_RGBCNT_STATUS_FAIL;
++    int rc = -1;
++
++    do
++    {
++        if (context->state == VF_STATE_INITIALIZED)
++        {
++            result = IR_RGBCNT_STATUS_OK;
++            break;
++        }
++        context->prev_color = NONE;
++        context->color = NONE;
++        context->red_cnt = 0;
++        context->green_cnt = 0;
++        context->blue_cnt = 0;
++
++        context->width = frame->width;
++        context->height = frame->height;
++        context->detph = (frame->width * 2 == frame->linesize[0]) ? 10 : 8;
++        context->linesize = (context->detph == 10) \
++                            ? frame->width * 2 : frame->width;
++        context->fps = inlink->frame_rate.num / (float) inlink->frame_rate.den;
++
++        context->rgb_size = av_image_get_buffer_size(AV_PIX_FMT_RGB24, \
++                                context->width, context->height, 1);
++        context->rgb_data = (uint8_t*)malloc(context->rgb_size);
++        if (context->rgb_data == NULL)
++        {
++            av_log(filter, AV_LOG_ERROR, "Can't allocate memory for RGB\n");
++            break;
++        }
++
++        context->pFrameRGB = av_frame_alloc();
++        if (context->pFrameRGB == NULL)
++        {
++            av_log(filter, AV_LOG_ERROR, "Can't allocate frame\n");
++            break;
++        }
++        rc = av_image_fill_arrays(context->pFrameRGB->data, \
++            context->pFrameRGB->linesize, context->rgb_data, AV_PIX_FMT_RGB24, \
++            context->width, context->height, 1);
++        if (rc < 0)
++        {
++            av_log(filter, AV_LOG_ERROR, "Error when filling arrays\n");
++            break;
++        }
++
++        context->state = VF_STATE_INITIALIZED;
++        result = IR_RGBCNT_STATUS_OK;
++
++    } while(0);
++
++    return result;
++}
++
++/**
++********************************************************************************
++* @name     Irdeto FFmpeg rgb counter get color routine
++* @brief    This functions decides whether the current frame is a red, green or 
++*           blue frame. This video filter is intended to be used with test 
++*           videos generated with command: ffmpeg -f lavi -i color=color=[red, 
++            green, blue] -t Time test_stream.mp4
++* @param    [in] ctx    Pointer to ir_rgb_context
++* @return   void
++********************************************************************************
++*/
++static void vf_get_color(struct ir_rgb_context* context)
++{
++    int i;
++    int red_pel = 0;
++    int green_pel = 0;
++    int blue_pel = 0;
++
++    for (i = 0; i < context->width * context->height * 3; i+=3)
++    {
++        /*  Image with green and blue channels equal to 0 and red channel 
++            greater than 230 is considered as a red frame for testing  */
++        if (context->pFrameRGB->data[0][i] >= 230 && \
++            context->pFrameRGB->data[0][i+1] == 0 && \
++            context->pFrameRGB->data[0][i+2] == 0)
++        {
++            red_pel++;
++        }
++        /*  Image with red and blue channels equal to 0 and green channel 
++            greater than 100 is considered as a green frame for testing  */
++        if (context->pFrameRGB->data[0][i] == 0 && \
++            context->pFrameRGB->data[0][i+1] >= 100 && \
++            context->pFrameRGB->data[0][i+2] == 0)
++        {
++            green_pel++;
++        }
++        /*  Image with red and green channels equal to 0 and blue channel 
++            greater than 230 is considered as a blue frame for testing  */
++        if (context->pFrameRGB->data[0][i] == 0 && \
++            context->pFrameRGB->data[0][i+1] == 0 && \
++            context->pFrameRGB->data[0][i+2] >= 230)
++        {
++            blue_pel++;
++        }
++    }
++
++    if (red_pel == context->width * context->height)
++    {
++        context->prev_color = context->color;
++        context->color = RED;
++        context->red_cnt++;
++    }
++    if (green_pel == context->width * context->height)
++    {
++        context->prev_color = context->color;
++        context->color = GREEN;
++        context->green_cnt++;
++    }
++    if (blue_pel == context->width * context->height)
++    {
++        context->prev_color = context->color;
++        context->color = BLUE;
++        context->blue_cnt++;
++    }
++}
++
++/**
++********************************************************************************
++* @brief        Process single frame
++* @note         FFmpeg AVFrame quick specification:
++*               int line_size_U = frame->linesize[1];
++*               int line_size_V = frame->linesize[2];
++*               uint8_t  *U     = frame->data[1];
++*               uint8_t  *V     = frame->data[2];
++*               uint32_t pict_size_Y = height*line_size_Y;
++*               uint32_t pict_size_U = (height>>irdeto->vsub)*line_size_U;
++*               uint32_t pict_size_V = (height>>irdeto->vsub)*line_size_V;
++*               inlink->w
++*               inlink->h
++*               inlink->sample_aspect_ratio
++*               inlink->frame_count
++*               frame->pts == AV_NOPTS_VALUE ? 
++*                   NAN : frame->pts * av_q2d(inlink->time_base);
++*               frame->pict_type;
++*               AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(inlink->format);
++*               irdeto->hsub = desc->log2_chroma_w;
++*               irdeto->vsub = desc->log2_chroma_h;
++* @return       IR_OTTWM_STATUS_OK on success, IR_OTTWM_STATUS_FAIL - otherwise
++********************************************************************************
++*/
++static IR_RGBCNT_STATUS vf_rgbcnt_process_frame(AVFilterLink* const inlink,
++    AVFrame* const frame)
++{
++    IR_RGBCNT_STATUS result = IR_RGBCNT_STATUS_FAIL;
++    AVFilterContext* filter = (AVFilterContext*) inlink->dst;
++    struct ir_rgb_context* context = (struct ir_rgb_context*) filter->priv;
++
++    do
++    {
++        /*  Scaling function that converts YUV frame into RGB representation  
++            YUV data cannot be used to determine whether frame is red, blue or 
++            green, as red and green frame has same Y value  */
++        struct SwsContext* sc;
++        sc = sws_getContext(context->width, context->height, frame->format, \
++                            context->width, context->height, AV_PIX_FMT_RGB24, \
++                            SWS_BICUBIC, NULL, NULL, NULL);
++        sws_scale(sc, (const uint8_t* const*)frame->data, frame->linesize, \
++                    0, frame->height, context->pFrameRGB->data, \
++                    context->pFrameRGB->linesize);
++
++        vf_get_color(context);
++        if (context->prev_color != context->color)
++        {
++            av_log(filter, AV_LOG_INFO, "Switch from color %s to color %s"
++                    " at frame number %"PRId64"\n", color_name[context->prev_color], 
++                    color_name[context->color], inlink->frame_count);
++        }
++
++        result = IR_RGBCNT_STATUS_OK;
++
++    } while(0);
++
++    return result;
++}
++/**
++********************************************************************************
++* @brief    This function called for every frame in the stream that will be
++*           filtered
++* @param    [in] inlink Pointer to input link of the AVFilter
++* @param    [in] frame  Pointer to Video frame decoded by FFmpeg
++* @return   0 on success, non-zero - otherwise
++********************************************************************************
++*/
++static int ff_rgbcnt_filter_frame(AVFilterLink* const inlink,
++    AVFrame* const frame)
++{
++    int sys = 0;
++    IR_RGBCNT_STATUS result = IR_RGBCNT_STATUS_BADARG;
++    AVFilterContext* ctx = (AVFilterContext*) inlink->dst;
++    
++    do
++    {
++        result = vf_rgbcnt_postinit(inlink, frame);
++        if (IR_RGBCNT_STATUS_OK != result)
++        {
++            sys = EPERM;
++            break;
++        }
++
++        result = vf_rgbcnt_process_frame(inlink, frame);
++        if (IR_RGBCNT_STATUS_OK != result)
++        {
++            sys = EPERM;
++            break;
++        }
++
++        sys = ff_filter_frame(ctx->outputs[0], frame);
++        
++    } while(0);
++
++    return AVERROR(sys);
++}
++
++/**
++********************************************************************************
++* @brief    Irdeto FFmpeg video filter uninitialization
++* @param    [in] ctx    Pointer to AVFilter context structure
++* @return   void
++********************************************************************************
++*/
++static av_cold void vf_rgbcnt_uninit(AVFilterContext* const ctx)
++{
++    struct ir_rgb_context* context = (struct ir_rgb_context*) ctx->priv;
++    free(context->rgb_data);
++    av_frame_free(&context->pFrameRGB);
++
++    av_log(ctx, AV_LOG_INFO, "red frame count: %d\n", context->red_cnt);
++    av_log(ctx, AV_LOG_INFO, "green frame count: %d\n", context->green_cnt);
++    av_log(ctx, AV_LOG_INFO, "blue frame count: %d\n", context->blue_cnt);
++    av_log(ctx, AV_LOG_INFO, "Irdeto rgb counter uninitialized.\n");
++}
++
++/**
++********************************************************************************
++* @brief    List pixel formats plugin will be able to count rgb frames
++* @param    [in] ctx    Pointer to Filter context
++* @note     This function will be called asyncronously by FFmpeg engine
++* @return   0
++********************************************************************************
++*/
++static int ir_rgbcnt_register_formats(AVFilterContext* const ctx)
++{
++    static const enum AVPixelFormat pix_fmts[] =
++    {
++        AV_PIX_FMT_YUV420P10,
++        AV_PIX_FMT_YUV422P10,
++        AV_PIX_FMT_YUV444P10,
++        AV_PIX_FMT_YUV420P,
++        AV_PIX_FMT_YUV422P,
++        AV_PIX_FMT_YUV444P,
++        AV_PIX_FMT_NONE
++    };
++
++    AVFilterFormats *fmts_list = ff_make_format_list(pix_fmts);
++    if (!fmts_list)
++    {
++        return AVERROR(ENOMEM);
++    }
++    return ff_set_common_formats(ctx, fmts_list);
++}
++
++/**
++********************************************************************************
++* @brief    Connector for the filter inputs
++********************************************************************************
++*/
++static const AVFilterPad ff_vf_rgbcnt_inputs[] =
++{
++    {
++        .name             = "default",
++        .type             = AVMEDIA_TYPE_VIDEO,
++        .get_video_buffer = ff_null_get_video_buffer,
++        .filter_frame     = ff_rgbcnt_filter_frame,
++        .config_props     = NULL,
++    },
++    { NULL }
++};
++
++/**
++********************************************************************************
++* @brief    Connector for the filter outputs
++********************************************************************************
++*/
++static const AVFilterPad ff_vf_rgbcnt_outputs[] =
++{
++    {
++        .name = "default",
++        .type = AVMEDIA_TYPE_VIDEO,
++    },
++    { NULL }
++};
++
++/**
++********************************************************************************
++* @brief    Irdeto RGB counter definition
++********************************************************************************
++*/
++AVFilter ff_vf_rgbcnt =
++{
++    .name            = "rgbcnt",
++    .description     = NULL_IF_CONFIG_SMALL("Irdeto custom rgb counter."),
++    .priv_size       = sizeof(struct ir_rgb_context),
++    .init            = vf_rgbcnt_init,
++    .uninit          = vf_rgbcnt_uninit,
++    .query_formats   = ir_rgbcnt_register_formats,
++    .inputs          = ff_vf_rgbcnt_inputs,
++    .outputs         = ff_vf_rgbcnt_outputs,
++};
+diff --git a/source/libavformat/mov.c b/source/libavformat/mov.c
+index 7266fd0..6541ecf 100644
+--- a/source/libavformat/mov.c
++++ b/source/libavformat/mov.c
+@@ -1396,6 +1396,28 @@ static int mov_read_fiel(MOVContext *c, AVIOContext *pb, MOVAtom atom)
+     return 0;
+ }
+ 
++/**
++********************************************************************************
++* @author       Fabian van der Werf (fabian.vanderwerf@irdeto.com)
++* @brief        Reading of ProRes clap atom
++* @param        [in] c      MOV context
++* @param        [in] pb     Input context
++* @param        [in]atom    MOV atom
++* @retrn        0 on succes, error code - otherwise
++********************************************************************************
++*/
++static int mov_read_clap(MOVContext *c, AVIOContext *pb, MOVAtom atom)
++{
++    AVStream *st;
++ 
++    if (c->fc->nb_streams < 1)
++        return 0;
++    st = c->fc->streams[c->fc->nb_streams-1];
++ 
++    avio_skip(pb, 8*4);
++    return av_dict_set_int(&(st->metadata), "mov.clap", 1, 0);
++}
++
+ static int mov_realloc_extradata(AVCodecParameters *par, MOVAtom atom)
+ {
+     int err = 0;
+@@ -4320,6 +4342,7 @@ static const MOVParseTableEntry mov_default_parse_table[] = {
+ { MKTAG('A','R','E','S'), mov_read_ares },
+ { MKTAG('a','v','s','s'), mov_read_avss },
+ { MKTAG('c','h','p','l'), mov_read_chpl },
++{ MKTAG('c','l','a','p'), mov_read_clap },  ///< Add CLAP parsing
+ { MKTAG('c','o','6','4'), mov_read_stco },
+ { MKTAG('c','o','l','r'), mov_read_colr },
+ { MKTAG('c','t','t','s'), mov_read_ctts }, /* composition time to sample */
+diff --git a/source/libavformat/mxf.h b/source/libavformat/mxf.h
+index f3db1f9..d1348f5 100644
+--- a/source/libavformat/mxf.h
++++ b/source/libavformat/mxf.h
+@@ -62,6 +62,14 @@ typedef struct KLVPacket {
+     UID key;
+     int64_t offset;
+     uint64_t length;
++    
++    /**
++    ****************************************************************************
++    * @author   Michael Verberne (michael.verberne@irdeto.com)
++    * @date     Jul 30, 2015
++    ****************************************************************************
++    */
++    uint64_t ber_size;
+ } KLVPacket;
+ 
+ typedef struct MXFCodecUL {
+diff --git a/source/libavformat/mxfdec.c b/source/libavformat/mxfdec.c
+index 0affca9..9f4969a 100644
+--- a/source/libavformat/mxfdec.c
++++ b/source/libavformat/mxfdec.c
+@@ -337,6 +337,29 @@ static void mxf_free_metadataset(MXFMetadataSet **ctx, int freectx)
+     av_freep(ctx);
+ }
+ 
++/**
++********************************************************************************
++* @author   Michael Verberne (michael.verberne@irdeto.com)
++* @date     Jul 30, 2015
++********************************************************************************
++*/
++static int64_t klv_decode_ber_length_ex(AVIOContext *pb, int64_t *ber_size)
++{
++    uint64_t size = avio_r8(pb);
++    *ber_size = 1;
++    if (size & 0x80) { /* long form */
++        int bytes_num = size & 0x7f;
++        /* SMPTE 379M 5.3.4 guarantee that bytes_num must not exceed 8 bytes */
++        if (bytes_num > 8)
++            return AVERROR_INVALIDDATA;
++        *ber_size += bytes_num;
++        size = 0;
++        while (bytes_num--)
++            size = size << 8 | avio_r8(pb);
++    }
++    return size;
++}
++
+ static int64_t klv_decode_ber_length(AVIOContext *pb)
+ {
+     uint64_t size = avio_r8(pb);
+@@ -372,7 +395,16 @@ static int klv_read_packet(KLVPacket *klv, AVIOContext *pb)
+     klv->offset = avio_tell(pb) - 4;
+     memcpy(klv->key, mxf_klv_key, 4);
+     avio_read(pb, klv->key + 4, 12);
+-    klv->length = klv_decode_ber_length(pb);
++
++    //klv->length = klv_decode_ber_length(pb);
++    
++    /**
++    ****************************************************************************
++    * @author   Michael Verberne (michael.verberne@irdeto.com)
++    * @date     Jul 30, 2015
++    ****************************************************************************
++    */
++    klv->length = klv_decode_ber_length_ex(pb, &klv->ber_size);
+     return klv->length == -1 ? -1 : 0;
+ }
+ 
+@@ -3006,6 +3038,14 @@ static int mxf_read_packet_old(AVFormatContext *s, AVPacket *pkt)
+             pkt->stream_index = index;
+             pkt->pos = klv.offset;
+ 
++            /**
++            ********************************************************************
++            * @author   Michael Verberne (michael.verberne@irdeto.com)
++            * @date     Jul 30, 2015
++            ********************************************************************
++            */
++            pkt->hdr_size = 16 + klv.ber_size;
++
+             par = st->codecpar;
+ 
+             if (par->codec_type == AVMEDIA_TYPE_VIDEO && next_ofs >= 0) {
+diff --git a/source/libavformat/utils.c b/source/libavformat/utils.c
+index d2a709c..bae4203 100644
+--- a/source/libavformat/utils.c
++++ b/source/libavformat/utils.c
+@@ -1358,6 +1358,15 @@ static int parse_packet(AVFormatContext *s, AVPacket *pkt, int stream_index)
+ 
+         pkt->pts = pkt->dts = AV_NOPTS_VALUE;
+         pkt->pos = -1;
++
++        /**
++        ************************************************************************
++        * @author   Michael Verberne (michael.verberne@irdeto.com)
++        * @date     Jul 30, 2015
++        ************************************************************************
++        */
++        out_pkt.hdr_size = pkt->hdr_size;
++
+         /* increment read pointer */
+         data += len;
+         size -= len;
+diff --git a/source/libavutil/frame.c b/source/libavutil/frame.c
+index d5c7c9f..9ab5313 100644
+--- a/source/libavutil/frame.c
++++ b/source/libavutil/frame.c
+@@ -294,6 +294,9 @@ static int frame_copy_props(AVFrame *dst, const AVFrame *src, int force_copy)
+     dst->palette_has_changed    = src->palette_has_changed;
+     dst->sample_rate            = src->sample_rate;
+     dst->opaque                 = src->opaque;
++#ifdef IRDETO
++    //dst->irdeto_export          = src->irdeto_export;
++#endif
+     dst->pkt_pts                = src->pkt_pts;
+     dst->pkt_dts                = src->pkt_dts;
+     dst->pkt_pos                = src->pkt_pos;
+@@ -368,6 +371,8 @@ FF_DISABLE_DEPRECATION_WARNINGS
+ FF_ENABLE_DEPRECATION_WARNINGS
+ #endif
+ 
++    dst->mb_type = src->mb_type;
++
+     return 0;
+ }
+ 
+@@ -461,6 +466,11 @@ int av_frame_ref(AVFrame *dst, const AVFrame *src)
+     memcpy(dst->data,     src->data,     sizeof(src->data));
+     memcpy(dst->linesize, src->linesize, sizeof(src->linesize));
+ 
++#ifdef IRDETO
++    dst->opaque = src->opaque;
++    //dst->irdeto_export = src->irdeto_export;
++#endif
++
+     return 0;
+ 
+ fail:
+diff --git a/source/libavutil/frame.h b/source/libavutil/frame.h
+index 2b5c332..d1921a6 100644
+--- a/source/libavutil/frame.h
++++ b/source/libavutil/frame.h
+@@ -294,6 +294,11 @@ typedef struct AVFrame {
+     int quality;
+ 
+     /**
++     * macroblock type table
++     * mb_type_base + mb_width + 2
++     */
++    uint32_t *mb_type;
++    /**
+      * for some private data of the user
+      */
+     void *opaque;
+@@ -385,6 +390,7 @@ typedef struct AVFrame {
+ 
+ /**
+  * @defgroup lavu_frame_flags AV_FRAME_FLAGS
++ * @ingroup lavu_frame
+  * Flags describing additional frame properties.
+  *
+  * @{
+@@ -501,13 +507,11 @@ typedef struct AVFrame {
+      * QP table
+      * Not to be accessed directly from outside libavutil
+      */
+-    attribute_deprecated
+     int8_t *qscale_table;
+     /**
+      * QP store stride
+      * Not to be accessed directly from outside libavutil
+      */
+-    attribute_deprecated
+     int qstride;
+ 
+     attribute_deprecated
+@@ -523,6 +527,14 @@ typedef struct AVFrame {
+      * AVHWFramesContext describing the frame.
+      */
+     AVBufferRef *hw_frames_ctx;
++
++#ifdef IRDETO
++    /** !mv
++     * For Irdeto specific data
++     */
++    //void *irdeto_export;
++#endif
++
+ } AVFrame;
+ 
+ /**
+diff --git a/source/libavutil/pixdesc.c b/source/libavutil/pixdesc.c
+index 0dffa4d..ae65d1c 100644
+--- a/source/libavutil/pixdesc.c
++++ b/source/libavutil/pixdesc.c
+@@ -131,6 +131,7 @@ void av_write_image_line(const uint16_t *src,
+ FF_DISABLE_DEPRECATION_WARNINGS
+ #endif
+ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
++#if 0
+     [AV_PIX_FMT_YUV420P] = {
+         .name = "yuv420p",
+         .nb_components = 3,
+@@ -143,6 +144,21 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+         },
+         .flags = AV_PIX_FMT_FLAG_PLANAR,
+     },
++#else
++    [AV_PIX_FMT_YUV420P] = {
++        .name = "yuv420p",
++        .nb_components = 4,
++        .log2_chroma_w = 1,
++        .log2_chroma_h = 1,
++        .comp = {
++            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
++            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
++            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
++            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec*/
++        },
++        .flags = AV_PIX_FMT_FLAG_PLANAR,
++    },
++#endif
+     [AV_PIX_FMT_YUYV422] = {
+         .name = "yuyv422",
+         .nb_components = 3,
+@@ -189,6 +205,8 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+         },
+         .flags = AV_PIX_FMT_FLAG_RGB,
+     },
++
++#if 0
+     [AV_PIX_FMT_YUV422P] = {
+         .name = "yuv422p",
+         .nb_components = 3,
+@@ -201,6 +219,23 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+         },
+         .flags = AV_PIX_FMT_FLAG_PLANAR,
+     },
++#else
++    [AV_PIX_FMT_YUV422P] = {
++        .name = "yuv422p",
++        .nb_components = 4,
++        .log2_chroma_w = 1,
++        .log2_chroma_h = 0,
++        .comp = {
++            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
++            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
++            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
++            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec*/
++        },
++        .flags = AV_PIX_FMT_FLAG_PLANAR,
++    },
++#endif
++
++#if 0
+     [AV_PIX_FMT_YUV444P] = {
+         .name = "yuv444p",
+         .nb_components = 3,
+@@ -213,6 +248,23 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+         },
+         .flags = AV_PIX_FMT_FLAG_PLANAR,
+     },
++#else
++    [AV_PIX_FMT_YUV444P] = {
++        .name = "yuv444p",
++        .nb_components = 4,
++        .log2_chroma_w = 0,
++        .log2_chroma_h = 0,
++        .comp = {
++            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
++            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
++            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
++            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec*/
++        },
++        .flags = AV_PIX_FMT_FLAG_PLANAR,
++    },
++#endif
++
++#if 0
+     [AV_PIX_FMT_YUV410P] = {
+         .name = "yuv410p",
+         .nb_components = 3,
+@@ -225,6 +277,22 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+         },
+         .flags = AV_PIX_FMT_FLAG_PLANAR,
+     },
++#else
++    [AV_PIX_FMT_YUV410P] = {
++        .name = "yuv410p",
++        .nb_components = 4,
++        .log2_chroma_w = 2,
++        .log2_chroma_h = 2,
++        .comp = {
++            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
++            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
++            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
++            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec */
++        },
++        .flags = AV_PIX_FMT_FLAG_PLANAR,
++    },
++#endif
++#if 0
+     [AV_PIX_FMT_YUV411P] = {
+         .name = "yuv411p",
+         .nb_components = 3,
+@@ -237,6 +305,22 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+         },
+         .flags = AV_PIX_FMT_FLAG_PLANAR,
+     },
++#else
++    [AV_PIX_FMT_YUV411P] = {
++        .name = "yuv411p",
++        .nb_components = 4,
++        .log2_chroma_w = 2,
++        .log2_chroma_h = 0,
++        .comp = {
++            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
++            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
++            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
++            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec */
++        },
++        .flags = AV_PIX_FMT_FLAG_PLANAR,
++    },
++#endif
++#if 0
+     [AV_PIX_FMT_YUVJ411P] = {
+         .name = "yuvj411p",
+         .nb_components = 3,
+@@ -249,6 +333,21 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+         },
+         .flags = AV_PIX_FMT_FLAG_PLANAR,
+     },
++#else
++   [AV_PIX_FMT_YUVJ411P] = {
++        .name = "yuvj411p",
++        .nb_components = 4,
++        .log2_chroma_w = 2,
++        .log2_chroma_h = 0,
++        .comp = {
++            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
++            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
++            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
++            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec */
++        },
++        .flags = AV_PIX_FMT_FLAG_PLANAR,
++    },
++#endif
+     [AV_PIX_FMT_GRAY8] = {
+         .name = "gray",
+         .nb_components = 1,
+@@ -290,6 +389,7 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+         },
+         .flags = AV_PIX_FMT_FLAG_PAL,
+     },
++#if 0
+     [AV_PIX_FMT_YUVJ420P] = {
+         .name = "yuvj420p",
+         .nb_components = 3,
+@@ -302,6 +402,22 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+         },
+         .flags = AV_PIX_FMT_FLAG_PLANAR,
+     },
++#else
++    [AV_PIX_FMT_YUVJ420P] = {
++        .name = "yuvj420p",
++        .nb_components = 4,
++        .log2_chroma_w = 1,
++        .log2_chroma_h = 1,
++        .comp = {
++            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
++            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
++            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
++            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec*/
++        },
++        .flags = AV_PIX_FMT_FLAG_PLANAR,
++    },
++#endif
++#if 0
+     [AV_PIX_FMT_YUVJ422P] = {
+         .name = "yuvj422p",
+         .nb_components = 3,
+@@ -314,6 +430,22 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+         },
+         .flags = AV_PIX_FMT_FLAG_PLANAR,
+     },
++#else
++    [AV_PIX_FMT_YUVJ422P] = {
++        .name = "yuvj422p",
++        .nb_components = 4,
++        .log2_chroma_w = 1,
++        .log2_chroma_h = 0,
++        .comp = {
++            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
++            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
++            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
++            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec */
++        },
++        .flags = AV_PIX_FMT_FLAG_PLANAR,
++    },
++#endif
++#if 0
+     [AV_PIX_FMT_YUVJ444P] = {
+         .name = "yuvj444p",
+         .nb_components = 3,
+@@ -326,6 +458,21 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+         },
+         .flags = AV_PIX_FMT_FLAG_PLANAR,
+     },
++#else
++    [AV_PIX_FMT_YUVJ444P] = {
++        .name = "yuvj444p",
++        .nb_components = 4,
++        .log2_chroma_w = 0,
++        .log2_chroma_h = 0,
++        .comp = {
++            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
++            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
++            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
++            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec */
++        },
++        .flags = AV_PIX_FMT_FLAG_PLANAR,
++    },
++#endif
+ #if FF_API_XVMC
+     [AV_PIX_FMT_XVMC_MPEG2_MC] = {
+         .name = "xvmcmc",
+@@ -581,6 +728,7 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+         },
+         .alias = "y16le",
+     },
++#if 0
+     [AV_PIX_FMT_YUV440P] = {
+         .name = "yuv440p",
+         .nb_components = 3,
+@@ -593,6 +741,22 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+         },
+         .flags = AV_PIX_FMT_FLAG_PLANAR,
+     },
++#else
++    [AV_PIX_FMT_YUV440P] = {
++        .name = "yuv440p",
++        .nb_components = 4,
++        .log2_chroma_w = 0,
++        .log2_chroma_h = 1,
++        .comp = {
++            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
++            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
++            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
++            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec */
++        },
++        .flags = AV_PIX_FMT_FLAG_PLANAR,
++    },
++#endif
++#if 0
+     [AV_PIX_FMT_YUVJ440P] = {
+         .name = "yuvj440p",
+         .nb_components = 3,
+@@ -605,6 +769,21 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+         },
+         .flags = AV_PIX_FMT_FLAG_PLANAR,
+     },
++#else
++    [AV_PIX_FMT_YUVJ440P] = {
++        .name = "yuvj440p",
++        .nb_components = 4,
++        .log2_chroma_w = 0,
++        .log2_chroma_h = 1,
++        .comp = {
++            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
++            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
++            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
++            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec */
++        },
++        .flags = AV_PIX_FMT_FLAG_PLANAR,
++    },
++#endif
+     [AV_PIX_FMT_YUV440P10LE] = {
+         .name = "yuv440p10le",
+         .nb_components = 3,
+@@ -616,6 +795,7 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+             { 2, 2, 0, 0, 10, 1, 9, 1 },        /* V */
+         },
+         .flags = AV_PIX_FMT_FLAG_PLANAR,
++
+     },
+     [AV_PIX_FMT_YUV440P10BE] = {
+         .name = "yuv440p10be",
+@@ -2271,6 +2451,7 @@ int av_pix_fmt_count_planes(enum AVPixelFormat pix_fmt)
+         planes[desc->comp[i].plane] = 1;
+     for (i = 0; i < FF_ARRAY_ELEMS(planes); i++)
+         ret += planes[i];
++//    fprintf(stderr, "av_pix_fmt_count_planes() %d", ret);
+     return ret;
+ }
+ 
+diff --git a/source/libavutil/timestamp.h b/source/libavutil/timestamp.h
+index f010a7e..02830ae 100644
+--- a/source/libavutil/timestamp.h
++++ b/source/libavutil/timestamp.h
+@@ -42,8 +42,24 @@
+  */
+ static inline char *av_ts_make_string(char *buf, int64_t ts)
+ {
+-    if (ts == AV_NOPTS_VALUE) snprintf(buf, AV_TS_MAX_STRING_SIZE, "NOPTS");
+-    else                      snprintf(buf, AV_TS_MAX_STRING_SIZE, "%"PRId64, ts);
++    // if (ts == AV_NOPTS_VALUE) snprintf(buf, AV_TS_MAX_STRING_SIZE, "NOPTS");
++    // else                      snprintf(buf, AV_TS_MAX_STRING_SIZE, "%"PRId64, ts);
++    
++	/**
++	****************************************************************************
++	* @author 	Maksym Koshel (maksym.koshel@irdeto.com)
++	* @brief 	C++11 compatibility fix
++	* @date 	Aug 4, 2015
++	****************************************************************************
++	*/
++	if (ts == AV_NOPTS_VALUE)
++	{
++		snprintf(buf, AV_TS_MAX_STRING_SIZE, "NOPTS");
++	}
++	else
++    {
++	   	snprintf(buf, AV_TS_MAX_STRING_SIZE, "%" PRId64, ts);
++    }
+     return buf;
+ }
+ 
diff --git a/packaging/rpm/rpm.spec b/packaging/rpm/rpm.spec
index 32dcfae..cdaac04 100644
--- a/packaging/rpm/rpm.spec
+++ b/packaging/rpm/rpm.spec
@@ -36,6 +36,7 @@ BuildRequires: 	doxygen
 BuildRequires:  zlib-devel
 BuildRequires:  yasm
 BuildRequires:  intel-opencl-1.2-devel
+BuildRequires: 	irdeto-ott-wm >= 2.0.0
 
 Requires:       zlib
 Requires:       intel-opencl-1.2
@@ -160,7 +161,7 @@ cd -
 /usr/lib64/libswscale.so*
 /usr/lib64/libavdevice.so*
 /usr/lib64/libavfilter.so*
-%doc %{package_name}/source/RELEASE_NOTES %{package_name}/RELEASE %{package_name}/source/LICENSE.md %{package_name}/source/COPYING.LGPLv2.1 %{package_name}/source/CREDITS %{package_name}/BUILDFILE %{package_name}/source/changes.diff
+%doc %{package_name}/source/RELEASE_NOTES %{package_name}/RELEASE %{package_name}/source/LICENSE.md %{package_name}/source/COPYING.LGPLv2.1 %{package_name}/source/CREDITS %{package_name}/BUILDFILE %{package_name}/changes.diff
 
 %files utils
 %defattr(-,root,root,-)
diff --git a/source/configure b/source/configure
index 5b069eb..477cb28 100755
--- a/source/configure
+++ b/source/configure
@@ -2982,6 +2982,7 @@ unix_protocol_deps="sys_un_h"
 unix_protocol_select="network"
 
 # filters
+irdeto_filter_extralibs="-ldl"
 afftfilt_filter_deps="avcodec"
 afftfilt_filter_select="fft"
 amovie_filter_deps="avcodec avformat"
diff --git a/source/libavcodec/avcodec.h b/source/libavcodec/avcodec.h
index 39713ed..360f171 100644
--- a/source/libavcodec/avcodec.h
+++ b/source/libavcodec/avcodec.h
@@ -1599,6 +1599,15 @@ typedef struct AVPacket {
 
     int64_t pos;                            ///< byte position in stream, -1 if unknown
 
+    /**
+    ****************************************************************************
+    * @author   Michael Verberne (michael.verberne@irdeto.com)
+    * @brief    Size of the header (16byte key + 1 + ber length>
+    * @date     Jul 30, 2015
+    ****************************************************************************
+    */
+    int64_t hdr_size;
+
 #if FF_API_CONVERGENCE_DURATION
     /**
      * @deprecated Same as the duration field, but as int64_t. This was required
diff --git a/source/libavcodec/avpacket.c b/source/libavcodec/avpacket.c
index 92186892..e28cc96 100644
--- a/source/libavcodec/avpacket.c
+++ b/source/libavcodec/avpacket.c
@@ -35,6 +35,14 @@ void av_init_packet(AVPacket *pkt)
     pkt->pts                  = AV_NOPTS_VALUE;
     pkt->dts                  = AV_NOPTS_VALUE;
     pkt->pos                  = -1;
+
+    /**
+    ****************************************************************************
+    * @author   Michael Verberne (michael.verberne@irdeto.com)
+    * @date     Jul 30, 2015
+    ****************************************************************************
+    */
+    pkt->hdr_size             = -1;
     pkt->duration             = 0;
 #if FF_API_CONVERGENCE_DURATION
 FF_DISABLE_DEPRECATION_WARNINGS
@@ -535,6 +543,14 @@ int av_packet_copy_props(AVPacket *dst, const AVPacket *src)
     dst->pts                  = src->pts;
     dst->dts                  = src->dts;
     dst->pos                  = src->pos;
+
+    /**
+    ****************************************************************************
+    * @author   Michael Verberne (michael.verberne@irdeto.com)
+    * @date     Jul 30, 2015
+    ****************************************************************************
+    */
+    dst->hdr_size             = src->hdr_size;
     dst->duration             = src->duration;
 #if FF_API_CONVERGENCE_DURATION
 FF_DISABLE_DEPRECATION_WARNINGS
diff --git a/source/libavcodec/h264.c b/source/libavcodec/h264.c
index a56f900..23ec622 100644
--- a/source/libavcodec/h264.c
+++ b/source/libavcodec/h264.c
@@ -692,18 +692,22 @@ static void decode_postinit(H264Context *h, int setup_finished)
 
     out     = h->delayed_pic[0];
     out_idx = 0;
-    for (i = 1; h->delayed_pic[i] &&
-                !h->delayed_pic[i]->f->key_frame &&
-                !h->delayed_pic[i]->mmco_reset;
-         i++)
-        if (h->delayed_pic[i]->poc < out->poc) {
-            out     = h->delayed_pic[i];
-            out_idx = i;
-        }
+
+    if(!h->enable_irdeto_wm) {
+        for (i = 1; h->delayed_pic[i] &&
+                    !h->delayed_pic[i]->f->key_frame &&
+                    !h->delayed_pic[i]->mmco_reset;
+             i++)
+            if (h->delayed_pic[i]->poc < out->poc) {
+                out     = h->delayed_pic[i];
+                out_idx = i;
+            }
+    }
     if (h->avctx->has_b_frames == 0 &&
         (h->delayed_pic[0]->f->key_frame || h->delayed_pic[0]->mmco_reset))
         h->next_outputed_poc = INT_MIN;
-    out_of_order = out->poc < h->next_outputed_poc;
+
+    out_of_order = h->enable_irdeto_wm ? 0 : (out->poc < h->next_outputed_poc);
 
     if (out_of_order || pics > h->avctx->has_b_frames) {
         out->reference &= ~DELAYED_PIC_REF;
@@ -1182,6 +1186,9 @@ static int output_frame(H264Context *h, AVFrame *dst, H264Picture *srcp)
         return ret;
 
     av_dict_set(&dst->metadata, "stereo_mode", ff_h264_sei_stereo_mode(&h->sei.frame_packing), 0);
+    
+    av_frame_set_qp_table(dst, av_buffer_ref(srcp->qscale_table_buf), h->mb_stride, 0);
+    dst->mb_type = srcp->mb_type;
 
     h->backup_width   = h->avctx->width;
     h->backup_height  = h->avctx->height;
@@ -1203,6 +1210,7 @@ static int output_frame(H264Context *h, AVFrame *dst, H264Picture *srcp)
                       (srcp->crop_top  >> vshift) * dst->linesize[i];
         dst->data[i] += off;
     }
+
     return 0;
 }
 
@@ -1310,6 +1318,19 @@ static int h264_decode_frame(AVCodecContext *avctx, void *data,
     if (buf_index < 0)
         return AVERROR_INVALIDDATA;
 
+    if (h->cur_pic_ptr == NULL)
+    	return AVERROR_INVALIDDATA;
+
+    if(h->enable_irdeto_wm) {
+        for(int i=0;i<h->mb_height;i++)
+            for(int j=0;j<h->mb_width;j++) {
+                int mbxy = i*h->mb_stride+j;
+
+                if(!(h->cbp_table[mbxy]||IS_INTRA16x16(h->cur_pic_ptr->mb_type[mbxy])))
+                    h->cur_pic_ptr->qscale_table[mbxy] = -h->cur_pic_ptr->qscale_table[mbxy]; // mark skipped blocks
+            }
+    }
+
     if (!h->cur_pic_ptr && h->nal_unit_type == NAL_END_SEQUENCE) {
         av_assert0(buf_index <= buf_size);
         goto out;
@@ -1339,6 +1360,11 @@ static int h264_decode_frame(AVCodecContext *avctx, void *data,
             if (!h->next_output_pic->recovered)
                 h->next_output_pic->f->flags |= AV_FRAME_FLAG_CORRUPT;
 
+            for(i = 0; i < h->nb_slice_ctx; i++){
+            	 if(h->slice_ctx[i].er.error_occurred)
+            		 h->next_output_pic->f->flags |= AV_FRAME_FLAG_CORRUPT;
+            }
+
             if (!h->avctx->hwaccel &&
                  (h->next_output_pic->field_poc[0] == INT_MAX ||
                   h->next_output_pic->field_poc[1] == INT_MAX)
@@ -1390,6 +1416,7 @@ static const AVOption h264_options[] = {
     {"is_avc", "is avc", offsetof(H264Context, is_avc), AV_OPT_TYPE_BOOL, {.i64 = 0}, 0, 1, 0},
     {"nal_length_size", "nal_length_size", offsetof(H264Context, nal_length_size), AV_OPT_TYPE_INT, {.i64 = 0}, 0, 4, 0},
     { "enable_er", "Enable error resilience on damaged frames (unsafe)", OFFSET(enable_er), AV_OPT_TYPE_BOOL, { .i64 = -1 }, -1, 1, VD },
+	{ "enable_irdeto_wm", "Change decoder behavior to work within Irdeto WM products", OFFSET(enable_irdeto_wm), AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VD },
     { NULL },
 };
 
@@ -1445,3 +1472,47 @@ AVCodec ff_h264_vdpau_decoder = {
     .priv_class     = &h264_vdpau_class,
 };
 #endif
+
+#if 0
+void SaveFrameXS(unsigned char *data, int width, int height, int stride, const char *name, int num)
+{
+	FILE *pFile;
+	char szFilename[32];
+	int  y;
+
+	sprintf(szFilename, "top_%s%d.pgm", name, num);
+	pFile = fopen(szFilename, "wb");
+	if (pFile == NULL)
+		return;
+
+	fprintf(pFile, "P5\n%d %d\n255\n", width, height);
+
+	for(y = 0; y < height/2; y++)
+		fwrite(data + y * 2 * stride, 1, width, pFile);
+
+	fclose(pFile);
+	sprintf(szFilename, "bot_%s%d.pgm", name, num);
+	pFile = fopen(szFilename, "wb");
+	if (pFile == NULL)
+		return;
+
+	fprintf(pFile, "P5\n%d %d\n255\n", width, height);
+
+	for(y = 0; y < height/2; y++)
+		fwrite(data + (y * 2 + 1) * stride, 1, width, pFile);
+
+	fclose(pFile);
+
+	sprintf(szFilename, "%s%d.pgm", name, num);
+	pFile = fopen(szFilename, "wb");
+	if (pFile == NULL)
+		return;
+
+	fprintf(pFile, "P5\n%d %d\n255\n", width, height);
+
+	for(y = 0; y < height; y++)
+		fwrite(data + y * stride, 1, width, pFile);
+
+	fclose(pFile);
+}
+#endif
diff --git a/source/libavcodec/h264.h b/source/libavcodec/h264.h
index 309f91d..28ce7ec 100644
--- a/source/libavcodec/h264.h
+++ b/source/libavcodec/h264.h
@@ -685,6 +685,8 @@ typedef struct H264Context {
     AVBufferPool *motion_val_pool;
     AVBufferPool *ref_index_pool;
     int ref2frm[MAX_SLICES][2][64];     ///< reference to frame number lists, used in the loop filter, the first 2 are for -2,-1
+
+    int enable_irdeto_wm;
 } H264Context;
 
 extern const uint16_t ff_h264_mb_sizes[4];
@@ -1001,4 +1003,8 @@ void ff_h264_free_tables(H264Context *h);
 
 void ff_h264_set_erpic(ERPicture *dst, H264Picture *src);
 
+#if 0
+void SaveFrameXS(unsigned char *data, int width, int height, int stride, const char *name, int num);
+#endif
+
 #endif /* AVCODEC_H264_H */
diff --git a/source/libavcodec/h264_mb_template.c b/source/libavcodec/h264_mb_template.c
index d5ea26a..2765347 100644
--- a/source/libavcodec/h264_mb_template.c
+++ b/source/libavcodec/h264_mb_template.c
@@ -187,9 +187,42 @@ static av_noinline void FUNC(hl_decode_mb)(const H264Context *h, H264SliceContex
             }
         }
 
+        /*
+         * copy predicted mb to plane 3
+         */
+        if(h->enable_irdeto_wm){
+			uint8_t *src = h->cur_pic.f->data[0] + ((mb_x << PIXEL_SHIFT) + mb_y * h->mb_stride) * 16;
+			uint8_t *dst = h->cur_pic.f->data[3] + ((mb_x << PIXEL_SHIFT) + mb_y * h->mb_stride) * 16;
+			int inc = h->mb_stride;
+			if (( (FRAME_MBAFF(h) && MB_MBAFF(sl)) || (!FRAME_MBAFF(h) && MB_FIELD(sl)))) {
+				inc *= 2;
+				if  (mb_y & 0x1) {
+					src -= 15 * h->mb_stride;
+					dst -= 15 * h->mb_stride;
+				}
+			}
+			for (i = 0; i < 16; i++) {
+				memcpy(dst, src, 16);
+				src += inc;
+				dst += inc;
+			}
+        }
+
         hl_decode_mb_idct_luma(h, sl, mb_type, SIMPLE, transform_bypass,
                                PIXEL_SHIFT, block_offset, linesize, dest_y, 0);
 
+#if 0
+        {
+		static int picno = 0;
+		if (h->mb_x >= h->mb_width -1 && h->mb_y >= h->mb_height -1) {
+			fprintf(stderr, "\npicno:%d FRAME_MBAFF(h):%d MB_MBAFF(h):%d  MB_FIELD(h):%d", picno, FRAME_MBAFF(h), MB_MBAFF(h), MB_FIELD(h));
+			SaveFrameXS((unsigned char *) h->cur_pic.f.data[3], h->width, h->height, h->linesize, "libav_pred_", picno);
+			SaveFrameXS((unsigned char *) h->cur_pic.f.data[0], h->width, h->height, h->linesize, "libav_dec_", picno);
+			picno++;
+			fprintf(stderr, "\n************");
+		}
+	}
+#endif
         if ((SIMPLE || !CONFIG_GRAY || !(h->flags & AV_CODEC_FLAG_GRAY)) &&
             (sl->cbp & 0x30)) {
             uint8_t *dest[2] = { dest_cb, dest_cr };
diff --git a/source/libavcodec/hevc.c b/source/libavcodec/hevc.c
index cb1263c..e2dbd9b 100644
--- a/source/libavcodec/hevc.c
+++ b/source/libavcodec/hevc.c
@@ -43,11 +43,235 @@
 
 const uint8_t ff_hevc_pel_weight[65] = { [2] = 0, [4] = 1, [6] = 2, [8] = 3, [12] = 4, [16] = 5, [24] = 6, [32] = 7, [48] = 8, [64] = 9 };
 
+
+#ifdef IRDETO
+static void hev_copy_vps(HEVCContext *s)
+{
+	uint32_t *data = ((HEVCIrdetoExport*)s->ref->irdeto_export)->vps;
+	int i = 0;
+
+	memset(data, 0, sizeof((HEVCIrdetoExport*)s->ref->irdeto_export)->vps);
+
+	data[i++] = s->ps.sps->vps_id;
+	data[i++] = s->ps.vps->vps_max_sub_layers;
+	data[i++] = s->ps.vps->vps_temporal_id_nesting_flag;
+	data[i++] = s->ps.vps->ptl.general_ptl.profile_space;
+	data[i++] = s->ps.vps->ptl.general_ptl.tier_flag;
+	data[i++] = s->ps.vps->ptl.general_ptl.profile_idc;
+	data[i++] = s->ps.vps->ptl.general_ptl.level_idc;
+
+	for (; i < 64; i++)
+		data[i] = 0;
+}
+
+static void hev_copy_sps(HEVCContext *s)
+{
+	uint32_t *data = ((HEVCIrdetoExport*)s->ref->irdeto_export)->sps;
+	int i = 0;
+
+	memset(data, 0, sizeof((HEVCIrdetoExport*)s->ref->irdeto_export)->sps);
+
+	data[i++] = s->ps.sps->vps_id;;
+	data[i++] = s->ps.sps->max_sub_layers;
+	data[i++] = s->ps.sps->sps_temporal_id_nesting_flag;
+	data[i++] = s->ps.pps->sps_id;
+	data[i++] = s->ps.sps->chroma_format_idc;
+	data[i++] = s->ps.sps->width; // !mv ??
+	data[i++] = s->ps.sps->height; // !mv ??;
+	data[i++] = s->ps.sps->bit_depth;
+	data[i++] = s->ps.sps->bit_depth_chroma;
+	data[i++] = s->ps.sps->log2_max_poc_lsb;
+	data[i++] = s->ps.sps->log2_min_cb_size;
+	data[i++] = s->ps.sps->log2_diff_max_min_coding_block_size;
+	data[i++] = s->ps.sps->log2_min_tb_size;
+	data[i++] = s->ps.sps->log2_max_trafo_size;
+	data[i++] = s->ps.sps->max_transform_hierarchy_depth_inter;
+	data[i++] = s->ps.sps->max_transform_hierarchy_depth_intra;
+	data[i++] = s->ps.sps->scaling_list_enable_flag;
+	data[i++] = s->ps.sps->amp_enabled_flag;
+	data[i++] = s->ps.sps->sao_enabled;
+	data[i++] = s->ps.sps->pcm_enabled_flag;
+	data[i++] = s->ps.sps->sps_temporal_mvp_enabled_flag;
+	data[i++] = s->ps.sps->sps_strong_intra_smoothing_enable_flag;
+	data[i++] = s->ps.sps->vui_present;
+	data[i++] = s->ps.sps->nb_st_rps;
+
+	for (; i < 64; i++)
+		data[i] = 0;
+}
+
+
+static void hev_copy_pps(HEVCContext *s)
+{
+	uint32_t *data = ((HEVCIrdetoExport*)s->ref->irdeto_export)->pps;
+	int i = 0;
+
+	memset(data, 0, sizeof((HEVCIrdetoExport*)s->ref->irdeto_export)->pps);
+
+	data[i++] = s->ps.pps->diff_cu_qp_delta_depth;
+	data[i++] = s->ps.pps->cb_qp_offset;
+	data[i++] = s->ps.pps->cr_qp_offset;
+	data[i++] = s->ps.pps->weighted_pred_flag;
+	data[i++] = s->ps.pps->weighted_bipred_flag;
+	data[i++] = s->ps.pps->cu_qp_delta_enabled_flag;
+	data[i++] = s->ps.pps->constrained_intra_pred_flag;
+	data[i++] = s->ps.pps->transquant_bypass_enable_flag;
+	data[i++] = s->ps.pps->transform_skip_enabled_flag;
+	data[i++] = s->ps.pps->entropy_coding_sync_enabled_flag;
+	data[i++] = s->ps.pps->sign_data_hiding_flag;
+	data[i++] = s->ps.pps->deblocking_filter_control_present_flag;
+	if (!s->ps.pps->deblocking_filter_control_present_flag) {
+		data[i++] = 0;
+	}
+	else {
+		data[i++] = s->ps.pps->deblocking_filter_override_enabled_flag;
+	}
+	data[i++] = s->ps.pps->disable_dbf;
+	data[i++] = s->ps.pps->beta_offset/2;
+	data[i++] = s->ps.pps->tc_offset/2;
+	data[i++] = s->ps.pps->lists_modification_present_flag;
+	data[i++] = s->ps.pps->cabac_init_present_flag;
+
+	for (; i < 64; i++)
+		data[i] = 0;
+}
+
+static void hev_copy_slc(HEVCContext *s)
+{
+	uint32_t *data = ((HEVCIrdetoExport*)s->ref->irdeto_export)->slc;
+	uint32_t i = 0, j, MAX_NUM_REF = 16, k;
+
+	memset(data, 0, sizeof((HEVCIrdetoExport*)s->ref->irdeto_export)->slc);
+
+	// margins, must be valid when exporting ref yuv pics
+	data[i++] = 0; // ?? MarginX
+	data[i++] = 0; // ?? marginY
+
+	// rps
+	// handle.write((const char *)&m_numberOfPictures, SIZE_OF_INT32);			// write it to 32bit int
+	if (s->sh.short_term_rps != NULL) {
+		data[i++] = s->sh.short_term_rps->num_delta_pocs;
+
+		//handle.write((const char *)&m_numberOfNegativePictures, SIZE_OF_INT32);
+		data[i++] = s->sh.short_term_rps->num_negative_pics;
+
+		// handle.write((const char *)&m_numberOfPositivePictures, SIZE_OF_INT32);
+		data[i++] = s->sh.short_term_rps->num_delta_pocs - s->sh.short_term_rps->num_negative_pics; // correct??
+
+		//handle.write((const char *)m_POC, SIZE_OF_INT32*MAX_NUM_REF_PICS);
+		for (j = 0; j <  MAX_NUM_REF; j++) {
+			if (j < s->sh.slice_rps.num_delta_pocs || j >= s->sh.long_term_rps.nb_refs + s->sh.slice_rps.num_delta_pocs) {
+				data[i++] = 0;
+			}
+			else {
+				data[i++] = s->sh.long_term_rps.poc [j - s->sh.slice_rps.num_delta_pocs];
+			}
+		}
+
+		//handle.write((const char *)m_deltaPOC, SIZE_OF_INT32*MAX_NUM_REF_PICS);
+		for (j = 0; j <  MAX_NUM_REF; j++) {
+			if (j < s->sh.short_term_rps->num_delta_pocs) {
+				data[i++] = s->sh.short_term_rps->delta_poc[j];
+			}
+			else {
+				data[i++] = 0;
+			}
+		}
+
+		//handle.write((const char *)m_used, SIZE_OF_CHAR*MAX_NUM_REF_PICS);
+		for (j = 0; j <  MAX_NUM_REF; j++) {
+			if (j < s->sh.short_term_rps->num_delta_pocs) {
+				data[i++] = s->sh.short_term_rps->used[j];
+			}
+			else if (j < s->sh.long_term_rps.nb_refs + s->sh.slice_rps.num_delta_pocs) {
+				data[i++] = s->sh.long_term_rps.used[j - s->sh.slice_rps.num_delta_pocs];
+			}
+			else {
+				data[i++] = 0;
+			}
+		}
+	}
+	else {
+		i+= 51;
+	}
+
+	data[i++] = s->nal_unit_type;
+	data[i++] = s->sh.slice_type;
+	data[i++] = s->sh.slice_qp;
+	data[i++] = s->poc;//??
+	data[i++] = 0; //s->??m_lastIDR SCSA does not write correct value.
+	data[i++] = 0; //m_bCheckLDC s->?? low delay check , tdectop, ln 632
+	data[i++] = s->sh.slice_loop_filter_across_slices_enabled_flag;
+	data[i++] = s->sh.collocated_list;
+	data[i++] = s->sh.collocated_ref_idx;
+	data[i++] = s->sh.nb_refs[L0]; // num_ref_idx_l0_active_minus1 + 1 or num_ref_idx_l0_default_active +1
+	data[i++] = s->sh.nb_refs[L1]; // num_ref_idx_l1_active_minus1 + 1 or num_ref_idx_l1_default_active +1
+
+	// (char *)m_refPOCList, SIZE_OF_INT32*(2 * (MAX_NUM_REF + 1))
+	for (k = 0; k < 2; k++) {
+		for (j = 0; j < MAX_NUM_REF; j++) {
+			if (s->ref->refPicList != NULL && s->ref->refPicList[k].ref[j] != NULL) {
+				data[i++] = s->ref->refPicList[k].ref[j]->poc;// ?? hevc_refs, 323
+			}
+			else {
+				data[i++] = 0;
+			}
+		}
+		data[i++] = 0; // ?? there is a maximum of 16 references, why MAX_NUM_REF + 1 ?
+	}
+
+	data[i++] = s->sh.max_num_merge_cand;
+	data[i++] = s->ps.sps->ctb_size; //?? m_endCUAddr see TDecCAVLC ln 1002
+	data[i++] = s->sh.deblocking_filter_override_flag;
+	data[i++] = s->sh.disable_deblocking_filter_flag;
+	data[i++] = s->sh.beta_offset/2;
+	data[i++] = s->sh.tc_offset/2;
+
+	// list modifications
+	int nb_refs = ff_hevc_frame_nb_refs(s);
+	data[i++] = s->ps.pps->lists_modification_present_flag;
+	if (s->ps.pps->lists_modification_present_flag && nb_refs > 1) 	{
+		if (s->sh.rpl_modification_flag[0]) 	{
+			data[i++] = av_ceil_log2(nb_refs);
+			for (j = 0; j < s->sh.nb_refs[L0]; j++) {
+				data[i++] = s->sh.list_entry_lx[0][j];
+			}
+		}
+		if (s->sh.rpl_modification_flag[1]) 	{
+			data[i++] = av_ceil_log2(nb_refs);
+			for (j = 0; j < s->sh.nb_refs[L1]; j++)	{
+				data[i++] = s->sh.list_entry_lx[1][j];
+			}
+		}
+	}
+
+	for (; i < 256; i++)
+		data[i] = 0;
+}
+
+
 /**
  * NOTE: Each function hls_foo correspond to the function foo in the
  * specification (HLS stands for High Level Syntax).
  */
 
+static AVFrame *hevc_av_frame_alloc(void)
+{
+	AVFrame *frame;
+
+	if ((frame = av_frame_alloc()) == NULL) {
+		return NULL;
+	}
+	return frame;
+}
+
+static void hevc_av_frame_free(AVFrame **frame)
+{
+	av_frame_free(frame);
+}
+
+#endif
+
 /**
  * Section 5.7
  */
@@ -705,6 +929,10 @@ static int hls_slice_header(HEVCContext *s)
             if (s->ps.pps->deblocking_filter_override_enabled_flag)
                 deblocking_filter_override_flag = get_bits1(gb);
 
+#ifdef IRDETO
+            sh->deblocking_filter_override_flag = deblocking_filter_override_flag; // !mv
+#endif
+
             if (deblocking_filter_override_flag) {
                 sh->disable_deblocking_filter_flag = get_bits1(gb);
                 if (!sh->disable_deblocking_filter_flag) {
@@ -2970,6 +3198,8 @@ static int verify_md5(HEVCContext *s, AVFrame *frame)
     return 0;
 }
 
+
+
 static int hevc_decode_frame(AVCodecContext *avctx, void *data, int *got_output,
                              AVPacket *avpkt)
 {
@@ -3013,6 +3243,12 @@ static int hevc_decode_frame(AVCodecContext *avctx, void *data, int *got_output,
     if (s->is_decoded) {
         av_log(avctx, AV_LOG_DEBUG, "Decoded frame with POC %d.\n", s->poc);
         s->is_decoded = 0;
+#ifdef IRDETO
+    	hev_copy_vps(s);
+    	hev_copy_sps(s);
+    	hev_copy_pps(s);
+    	hev_copy_slc(s);
+#endif
     }
 
     if (s->output_frame->buf[0]) {
@@ -3079,11 +3315,20 @@ static av_cold int hevc_decode_free(AVCodecContext *avctx)
         av_freep(&s->sao_pixel_buffer_h[i]);
         av_freep(&s->sao_pixel_buffer_v[i]);
     }
+#ifdef IRDETO
+    hevc_av_frame_free(&s->output_frame);
+#else
     av_frame_free(&s->output_frame);
+#endif
 
     for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {
         ff_hevc_unref_frame(s, &s->DPB[i], ~0);
+#ifdef IRDETO
+        av_free(s->DPB[i].irdeto_export);
+        hevc_av_frame_free(&s->DPB[i].frame);
+#else
         av_frame_free(&s->DPB[i].frame);
+#endif
     }
 
     for (i = 0; i < FF_ARRAY_ELEMS(s->ps.vps_list); i++)
@@ -3133,15 +3378,26 @@ static av_cold int hevc_init_context(AVCodecContext *avctx)
     if (!s->cabac_state)
         goto fail;
 
+#ifdef IRDETO
+    s->output_frame = hevc_av_frame_alloc();
+#else
     s->output_frame = av_frame_alloc();
+#endif
     if (!s->output_frame)
         goto fail;
 
     for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {
+#ifdef IRDETO
+        s->DPB[i].frame = hevc_av_frame_alloc();
+#else
         s->DPB[i].frame = av_frame_alloc();
+#endif
         if (!s->DPB[i].frame)
             goto fail;
         s->DPB[i].tf.f = s->DPB[i].frame;
+#ifdef IRDETO
+        s->DPB[i].irdeto_export = av_mallocz(sizeof(HEVCIrdetoExport));
+#endif
     }
 
     s->max_ra = INT_MAX;
diff --git a/source/libavcodec/hevc.h b/source/libavcodec/hevc.h
index be91010..5192584 100644
--- a/source/libavcodec/hevc.h
+++ b/source/libavcodec/hevc.h
@@ -43,6 +43,8 @@
 #define MAX_NB_THREADS 16
 #define SHIFT_CTB_WPP 2
 
+#define IRDETO
+
 /**
  * 7.4.2.1
  */
@@ -88,6 +90,19 @@
                    (s)->nal_unit_type == NAL_BLA_N_LP)
 #define IS_IRAP(s) ((s)->nal_unit_type >= 16 && (s)->nal_unit_type <= 23)
 
+#ifdef IRDETO
+/**
+ * data exports, goes to opaque.
+ */
+typedef struct  HEVCIrdetoExport {
+	uint32_t vps[64];
+	uint32_t sps[64];
+	uint32_t pps[64];
+	uint32_t slc[256]; 	// data file containing margins and slice header data
+} HEVCIrdetoExport;
+
+#endif
+
 /**
  * Table 7-3: NAL unit type codes
  */
@@ -398,6 +413,9 @@ typedef struct ScalingList {
 
 typedef struct HEVCSPS {
     unsigned vps_id;
+#ifdef IRDETO
+    uint8_t sps_temporal_id_nesting_flag;
+#endif
     int chroma_format_idc;
     uint8_t separate_colour_plane_flag;
 
@@ -408,6 +426,9 @@ typedef struct HEVCSPS {
     HEVCWindow pic_conf_win;
 
     int bit_depth;
+#ifdef IRDETO
+    int bit_depth_chroma;
+#endif
     int pixel_shift;
     enum AVPixelFormat pix_fmt;
 
@@ -421,6 +442,9 @@ typedef struct HEVCSPS {
         int max_latency_increase;
     } temporal_layer[MAX_SUB_LAYERS];
 
+#ifdef IRDETO
+    uint8_t vui_present;
+#endif
     VUI vui;
     PTL ptl;
 
@@ -451,6 +475,9 @@ typedef struct HEVCSPS {
     unsigned int log2_min_cb_size;
     unsigned int log2_diff_max_min_coding_block_size;
     unsigned int log2_min_tb_size;
+#ifdef IRDETO
+    unsigned int log2_diff_max_min_transform_block_size;
+#endif
     unsigned int log2_max_trafo_size;
     unsigned int log2_ctb_size;
     unsigned int log2_min_pu_size;
@@ -645,6 +672,10 @@ typedef struct SliceHeader {
     int16_t chroma_offset_l1[16][2];
 
     int slice_ctb_addr_rs;
+
+#ifdef IRDETO
+    uint8_t deblocking_filter_override_flag; //!mv
+#endif
 } SliceHeader;
 
 typedef struct CodingUnit {
@@ -745,6 +776,10 @@ typedef struct HEVCFrame {
      * A combination of HEVC_FRAME_FLAG_*
      */
     uint8_t flags;
+
+#ifdef IRDETO
+    HEVCIrdetoExport *irdeto_export;
+#endif
 } HEVCFrame;
 
 typedef struct HEVCLocalContext {
@@ -790,6 +825,107 @@ typedef struct HEVCLocalContext {
     int boundary_flags;
 } HEVCLocalContext;
 
+
+#ifdef IRDETO
+/*
+JRen : Store header info from original stream
+*/
+typedef struct
+{
+	uint32_t vps_id;
+	uint32_t maxTempSubLayers;
+	uint32_t temporalIdNestingFlag;
+	uint32_t profileSpace;
+	uint32_t tier_flag;
+	uint32_t profile_idc;
+	uint32_t level_idc;
+} HEVCExportVps;
+
+typedef struct
+{
+	int32_t vps_id;
+	uint32_t bTemporalIdNestingFlag;
+	uint32_t sps_id;
+	uint32_t bitDepthY;
+	uint32_t bitDepthC;
+	uint32_t scalingListEnabledFlag;
+	uint32_t bUsePCM;
+	uint32_t bVuiPresent;
+
+	uint32_t chromaFormatIdc;
+	uint32_t picWidthInLumaSamples;
+	uint32_t picHeightInLumaSamples;
+
+	uint32_t numCuInWidth; 			// !mv not used
+	uint32_t numCuInHeight; 		// !mv not used
+	uint32_t numCUsInFrame; 		// !mv not used
+	uint32_t numPartitions; 		// !mv not used
+	uint32_t numPartInCUSize; 		// !mv not used
+
+	uint32_t numBitsForPoc;
+	uint32_t log2MinCodingBlockSize;
+	uint32_t log2DiffMaxMinCodingBlockSize;
+
+	uint32_t quadtreeTULog2MaxSize;
+	uint32_t quadtreeTULog2MinSize;
+
+	uint32_t quadtreeTUMaxDepthInter;
+	uint32_t quadtreeTUMaxDepthIntra;
+
+	uint32_t bUseSAO;
+	uint32_t bUseAMP;
+	uint32_t maxAMPDepth; 			// !mv not used
+
+	uint32_t maxTempSubLayers;   	// max number of Temporal Sub layers
+
+	uint32_t maxDecPicBuffering; 	// !mv not used these are dups of VPS values
+	uint32_t maxLatencyIncrease; 	// !mv not used
+	uint32_t numReorderPics; 		// !mv not used
+
+	uint32_t bUseStrongIntraSmoothing;
+	uint32_t bTemporalMVPEnabled;
+
+	uint32_t num_short_term_ref_pic_sets;
+} HEVCExportSps;;
+
+typedef struct
+{
+	uint32_t maxCuDQPDepth;
+
+	int      chromaQpOffset[2];      // use param
+
+	uint32_t     bUseWeightPred;         // use param
+	uint32_t     bUseWeightedBiPred;     // use param
+	uint32_t     bUseDQP;
+	uint32_t     bConstrainedIntraPred;  // use param
+
+	uint32_t     bTransquantBypassEnabled;  // Indicates presence of cu_transquant_bypass_flag in CUs.
+	uint32_t     bTransformSkipEnabled;     // use param
+	uint32_t     bEntropyCodingSyncEnabled; // use param
+	uint32_t     bSignHideEnabled;          // use param
+
+	uint32_t     bDeblockingFilterControlPresent;
+	uint32_t     bDeblockingFilterOverrideEnabledFlag;			// JRen : new added
+	uint32_t     bPicDisableDeblockingFilter;
+	int      deblockingFilterBetaOffsetDiv2;
+	int      deblockingFilterTcOffsetDiv2;
+
+	uint32_t	bListsModificationPresentFlag;					// JRen : new added
+	uint32_t	cabac_init_present_flag;						// JRen: SCR24594
+
+	// James : tile structure
+	uint32_t	bTilesEnabledFlag;		// !mv not used
+	uint32_t	bUniformSpacingFlag; // !mv not used
+	int		m_numTileColumnsMinus1; // !mv not used
+	int		m_numTileRowsMinus1; // !mv not used
+	int *	m_tileColumnWidth; // !mv not used
+	int *	m_tileRowHeight; // !mv not used
+	uint32_t	bLoopFilterAcrossTilesEnabledFlag; // !mv not used
+} HEVCExportPps;
+
+#endif
+
+
 typedef struct HEVCContext {
     const AVClass *c;  // needed by private avoptions
     AVCodecContext *avctx;
@@ -812,6 +948,9 @@ typedef struct HEVCContext {
 
     AVFrame *frame;
     AVFrame *output_frame;
+#ifdef IRDETO
+  //  HEVCIrdetoExport *irdeto_export;
+#endif
     uint8_t *sao_pixel_buffer_h[3];
     uint8_t *sao_pixel_buffer_v[3];
 
@@ -832,6 +971,9 @@ typedef struct HEVCContext {
     HEVCFrame DPB[32];
     int poc;
     int pocTid0;
+#ifdef IRDETO
+    int poc_lastIdr; // !mv
+#endif
     int slice_idx; ///< number of the slice being currently decoded
     int eos;       ///< current packet contains an EOS/EOB NAL
     int last_eos;  ///< last packet contains an EOS/EOB NAL
@@ -924,6 +1066,8 @@ typedef struct HEVCContext {
 
 } HEVCContext;
 
+
+
 int ff_hevc_decode_short_term_rps(GetBitContext *gb, AVCodecContext *avctx,
                                   ShortTermRPS *rps, const HEVCSPS *sps, int is_slice_header);
 
diff --git a/source/libavcodec/hevc_ps.c b/source/libavcodec/hevc_ps.c
index 83f2ec2..b068f79 100644
--- a/source/libavcodec/hevc_ps.c
+++ b/source/libavcodec/hevc_ps.c
@@ -840,7 +840,11 @@ int ff_hevc_parse_sps(HEVCSPS *sps, GetBitContext *gb, unsigned int *sps_id,
         return AVERROR_INVALIDDATA;
     }
 
+#ifdef IRDETO
+    sps->sps_temporal_id_nesting_flag = get_bits1(gb);
+#else
     skip_bits1(gb); // temporal_id_nesting_flag
+#endif
 
     if ((ret = parse_ptl(gb, avctx, &sps->ptl, sps->max_sub_layers)) < 0)
         return ret;
@@ -896,6 +900,10 @@ int ff_hevc_parse_sps(HEVCSPS *sps, GetBitContext *gb, unsigned int *sps_id,
 
     sps->bit_depth   = get_ue_golomb_long(gb) + 8;
     bit_depth_chroma = get_ue_golomb_long(gb) + 8;
+
+#ifdef IRDETO
+    sps->bit_depth_chroma = bit_depth_chroma;
+#endif
     if (sps->chroma_format_idc && bit_depth_chroma != sps->bit_depth) {
         av_log(avctx, AV_LOG_ERROR,
                "Luma bit depth (%d) is different from chroma bit depth (%d), "
@@ -1036,6 +1044,11 @@ int ff_hevc_parse_sps(HEVCSPS *sps, GetBitContext *gb, unsigned int *sps_id,
     sps->sps_strong_intra_smoothing_enable_flag = get_bits1(gb);
     sps->vui.sar = (AVRational){0, 1};
     vui_present = get_bits1(gb);
+
+#ifdef IRDETO
+    sps->vui_present = vui_present;
+#endif
+
     if (vui_present)
         decode_vui(gb, avctx, apply_defdispwin, sps);
 
diff --git a/source/libavcodec/hevc_refs.c b/source/libavcodec/hevc_refs.c
index 611ad45..157962c 100644
--- a/source/libavcodec/hevc_refs.c
+++ b/source/libavcodec/hevc_refs.c
@@ -209,6 +209,10 @@ int ff_hevc_output_frame(HEVCContext *s, AVFrame *out, int flush)
             int pixel_shift = !!(desc->comp[0].depth > 8);
 
             ret = av_frame_ref(out, src);
+#ifdef IRDETO
+            dst->opaque = frame->irdeto_export; //!mv not necessary, see copy_props() in av_frame_ref()
+#endif
+
             if (frame->flags & HEVC_FRAME_FLAG_BUMPING)
                 ff_hevc_unref_frame(s, frame, HEVC_FRAME_FLAG_OUTPUT | HEVC_FRAME_FLAG_BUMPING);
             else
diff --git a/source/libavfilter/Makefile b/source/libavfilter/Makefile
index 65a831e..d76f455 100644
--- a/source/libavfilter/Makefile
+++ b/source/libavfilter/Makefile
@@ -126,6 +126,8 @@ OBJS-$(CONFIG_BENCH_FILTER)                  += f_bench.o
 OBJS-$(CONFIG_BLACKDETECT_FILTER)            += vf_blackdetect.o
 
 # video filters
+OBJS-$(CONFIG_IRDETO_FILTER) 				 += vf_ott_wm.o
+OBJS-$(CONFIG_RGBCNT_FILTER) 				 += vf_rgb_cnt.o
 OBJS-$(CONFIG_BLACKFRAME_FILTER)             += vf_blackframe.o
 OBJS-$(CONFIG_BLEND_FILTER)                  += vf_blend.o dualinput.o framesync.o
 OBJS-$(CONFIG_BOXBLUR_FILTER)                += vf_boxblur.o
diff --git a/source/libavfilter/allfilters.c b/source/libavfilter/allfilters.c
index d0d491e..c224c78 100644
--- a/source/libavfilter/allfilters.c
+++ b/source/libavfilter/allfilters.c
@@ -135,6 +135,8 @@ void avfilter_register_all(void)
 
     REGISTER_FILTER(ANULLSINK,      anullsink,      asink);
 
+    REGISTER_FILTER(IRDETO,         irdeto,         vf);
+    REGISTER_FILTER(RGBCNT,         rgbcnt,         vf);
     REGISTER_FILTER(ALPHAEXTRACT,   alphaextract,   vf);
     REGISTER_FILTER(ALPHAMERGE,     alphamerge,     vf);
     REGISTER_FILTER(ATADENOISE,     atadenoise,     vf);
diff --git a/source/libavfilter/vf_ott_cmd.h b/source/libavfilter/vf_ott_cmd.h
new file mode 100644
index 0000000..2a8c23e
--- /dev/null
+++ b/source/libavfilter/vf_ott_cmd.h
@@ -0,0 +1,220 @@
+/*
+* Copyright (c) 2013-2016 Irdeto B.V.
+*
+* This file is part of FFmpeg.
+*
+* FFmpeg is free software; you can redistribute it and/or
+* modify it under the terms of the GNU Lesser General Public
+* License as published by the Free Software Foundation; either
+* version 2.1 of the License, or (at your option) any later version.
+*
+* FFmpeg is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+* Lesser General Public License for more details.
+*
+* You should have received a copy of the GNU Lesser General Public
+* License along with FFmpeg; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+*/
+
+#ifndef _VF_OTT_CMD_H_
+#define _VF_OTT_CMD_H_
+
+// FFmpeg libavutil includes
+#include "libavutil/opt.h"
+
+// Irdeto AVFilter context include
+#include "vf_ott_ctx.h"
+
+/**
+********************************************************************************
+* @def      IR_CMD_OFFSET
+* @brief    List of options for the filter set through the var=value syntax by
+*           the offset of the structure
+********************************************************************************
+*/
+#define IR_CMD_OFFSET(x) offsetof(struct ir_pf_context, x)
+
+/**
+********************************************************************************
+* @def      IR_CMD_FLAGS
+* @brief    Command line option flags definition for Irdeto video filter
+********************************************************************************
+*/
+#define IR_CMD_FLAGS (AV_OPT_FLAG_FILTERING_PARAM | AV_OPT_FLAG_VIDEO_PARAM)
+
+/**
+********************************************************************************
+* @brief        Irdeto post filter command line options
+********************************************************************************
+*/
+static const AVOption irdeto_options[] =
+{
+    {
+        "firstbit",
+        "Starting bit position (included) for the watermark embedding",
+        IR_CMD_OFFSET(config.firstbit),
+        AV_OPT_TYPE_INT,
+        {
+            .i64 = 0
+        },
+        0,
+        127,
+        IR_CMD_FLAGS
+    },
+    {
+        "lastbit",
+        "Ending bit position (included) for the watermark embedding",
+        IR_CMD_OFFSET(config.lastbit),
+        AV_OPT_TYPE_INT,
+        {
+            .i64 = 127
+        },
+        0,
+        127,
+        IR_CMD_FLAGS
+    },
+    {
+        "firstframe",
+        "First frame of the decoded video stream to be watermarked. "
+        "All frames in [firstframe, lastframe] will be watermarked",
+        IR_CMD_OFFSET(config.firstframe),
+        AV_OPT_TYPE_INT,
+        {
+            .i64 = 0
+        },
+        0,
+        INT_MAX,
+        IR_CMD_FLAGS
+    },
+    {
+        "lastframe",
+        "Last frame of the decoded video stream to be watermarked. "
+        "All frames in [firstframe, lastframe] will be watermarked",
+        IR_CMD_OFFSET(config.lastframe),
+        AV_OPT_TYPE_INT,
+        {
+            .i64 = INT_MAX
+        },
+        0,
+        INT_MAX,
+        IR_CMD_FLAGS
+    },
+    {
+        "lbtop",
+        "Number of lines from the top of the picture to be skipped for the "
+        "watermarked embedding, to compensate for letterboxes",
+        IR_CMD_OFFSET(config.lbtop),
+        AV_OPT_TYPE_INT,
+        {
+            .i64 = 0
+        },
+        0,
+        INT_MAX,
+        IR_CMD_FLAGS
+    },
+    {
+        "lbbottom",
+        "Number of lines from the bottom of the picture to be skipped for the "
+        "watermarked embedding, to compensate for letterboxes",
+        IR_CMD_OFFSET(config.lbbottom),
+        AV_OPT_TYPE_INT,
+        {
+            .i64 = 0
+        },
+        0,
+        INT_MAX,
+        IR_CMD_FLAGS
+    },
+    {
+        "operator",
+        "Operator ID to be used for the embedding",
+        IR_CMD_OFFSET(config.id),
+        AV_OPT_TYPE_INT,
+        {
+            .i64 = -1
+        },
+        -1,
+        1023,
+        IR_CMD_FLAGS
+    },
+    {
+        "tmid",
+        "Identifier to be embedded over time in the video stream",
+        IR_CMD_OFFSET(tmid),
+        AV_OPT_TYPE_STRING,
+        {
+            .str = NULL
+        },
+        CHAR_MIN,
+        CHAR_MAX,
+        IR_CMD_FLAGS
+    },
+    {
+        "wmtime",
+        "Duration of each embedded bit in milliseconds "
+        "(exclusive with wmframes)",
+        IR_CMD_OFFSET(config.wmtime),
+        AV_OPT_TYPE_INT,
+        {
+            .i64 = 0
+        },
+        0,
+        LONG_MAX,
+        IR_CMD_FLAGS
+    },
+    {
+        "wmframes",
+        "Duration of each embedded bit in frames (exclusive with wmtime)",
+        IR_CMD_OFFSET(config.wmframes),
+        AV_OPT_TYPE_INT,
+        {
+            .i64 = 0
+        },
+        0,
+        LONG_MAX,
+        IR_CMD_FLAGS
+    },
+    {
+        "postfilter",
+        "Post-filter power for each frame. If 0 no post-filter will be applied.",
+        IR_CMD_OFFSET(config.pfe),
+        AV_OPT_TYPE_INT,
+        {
+            .i64 = 0
+        },
+        0,
+        25,
+        IR_CMD_FLAGS
+    },
+    {
+        "debug",
+        "AVFilter debug mode. 0 is disabled, 1 is printing of debug banner, "
+        "2 is watermark diff",
+        IR_CMD_OFFSET(config.mode),
+        AV_OPT_TYPE_INT,
+        {
+            .i64 = 0
+        },
+        0,
+        3,
+        IR_CMD_FLAGS
+    },
+    {
+        "str-file",
+        "File which contains information about GOP structure in the file "
+        "after first pass encode, to be used in wm splice boundary decisions",
+        IR_CMD_OFFSET(gopstr),
+        AV_OPT_TYPE_STRING,
+        {
+            .str = NULL
+        },
+        0,
+        3,
+        IR_CMD_FLAGS
+    },
+    { NULL }
+};
+
+#endif  /* !_VF_OTT_CMD_H_ */
diff --git a/source/libavfilter/vf_ott_ctx.h b/source/libavfilter/vf_ott_ctx.h
new file mode 100644
index 0000000..6fe3a8c
--- /dev/null
+++ b/source/libavfilter/vf_ott_ctx.h
@@ -0,0 +1,118 @@
+/*
+* Copyright (c) 2013-2016 Irdeto B.V.
+*
+* This file is part of FFmpeg.
+*
+* FFmpeg is free software; you can redistribute it and/or
+* modify it under the terms of the GNU Lesser General Public
+* License as published by the Free Software Foundation; either
+* version 2.1 of the License, or (at your option) any later version.
+*
+* FFmpeg is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+* Lesser General Public License for more details.
+*
+* You should have received a copy of the GNU Lesser General Public
+* License along with FFmpeg; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+*/
+
+#ifndef _VF_OTT_CTX_H_
+#define _VF_OTT_CTX_H_
+
+#include <stdint.h>
+
+// Irdeto OTT WM main data types
+#include <irottwm/ir_ott_wm.h>
+
+#define VF_OTT_VERSION_MAJOR    1
+#define VF_OTT_VERSION_MIDDLE   2
+#define VF_OTT_VERSION_MINOR    2
+#define VF_OTT_RELEASE          0
+
+/**
+********************************************************************************
+* @enum         VF_STATE
+* @brief        Video filter states representation
+********************************************************************************
+*/
+typedef enum
+{
+    VF_STATE_UNINITIALIZED  = 0,    ///< Video filter uninitialized
+    VF_STATE_INITIALIZED    = 1     ///< Video filter initialized
+} VF_STATE;
+
+/**
+********************************************************************************
+* @struct       ir_pf_context
+* @brief        Irdeto Video Filter context structure
+* @note         wmtime and wmframes replicate the same meaning which WM symbol
+*               duration. In the filter wmframes will be used all the time.
+*               wmtime will be converted to number of frames if it will be set
+********************************************************************************
+*/
+typedef struct ir_pf_context
+{
+    const AVClass*  class;      ///< FFmpeg class pointer
+
+    /*
+    ****************************************************************************
+    * Members will be filled by FFmpeg command line arguments parsing
+    ****************************************************************************
+    */
+    char*           tmid;       ///< String representation of TMID
+    char*           gopstr;     ///< Filepath of GOP structure description
+
+    /**
+    ****************************************************************************
+    * @brief    WM configuration will be passed to library. Partially will be
+    *           filled through FFmpeg AVFilter initialization
+    * @see      vf_ott_cmd.h
+    ****************************************************************************
+    */
+    struct ir_ottwm_config config;  ///< Configuration of WM library
+
+    /**
+    ****************************************************************************
+    * @brief    Numerical representation of TMID. This value will be passed to
+    *           WM library
+    ****************************************************************************
+    */
+    tmid_t          tmid_num;
+
+    /**
+    ****************************************************************************
+    * @brief    Handle of watermarking library (returned by dlopen)
+    ****************************************************************************
+    */
+    void*            wm_handle;
+
+    /**
+    ****************************************************************************
+    * @brief    Context of the WM library
+    ****************************************************************************
+    */
+    ir_ottwm_context embedder;
+
+    f_ir_init        wm_init;       ///< Initialization routine
+    f_ir_uninit      wm_uninit;     ///< Uninitialization routine
+    f_ir_version     wm_version;    ///< Get version routine
+    f_ir_embed       wm_embed;      ///< Process next frame routine
+
+    /**
+    ****************************************************************************
+    * @brief    Place holder for the logs comming out from the library
+    ****************************************************************************
+    */
+    char* log_buffer;
+
+    /**
+    ****************************************************************************
+    * @brief    Indication of the WM plugin state in current moment of time
+    ****************************************************************************
+    */
+    VF_STATE state;
+} IrdetoContext;
+
+#endif /* !_VF_OTT_CTX_H_ */
diff --git a/source/libavfilter/vf_ott_wm.c b/source/libavfilter/vf_ott_wm.c
new file mode 100644
index 0000000..e282096
--- /dev/null
+++ b/source/libavfilter/vf_ott_wm.c
@@ -0,0 +1,717 @@
+/*
+* Copyright (c) 2013-2016 Irdeto B.V.
+*
+* This file is part of FFmpeg.
+*
+* FFmpeg is free software; you can redistribute it and/or
+* modify it under the terms of the GNU Lesser General Public
+* License as published by the Free Software Foundation; either
+* version 2.1 of the License, or (at your option) any later version.
+*
+* FFmpeg is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+* Lesser General Public License for more details.
+*
+* You should have received a copy of the GNU Lesser General Public
+* License along with FFmpeg; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+*/
+
+// Global system includes
+#include <unistd.h>
+#include <dlfcn.h>
+#include <stdio.h>
+#include <string.h>
+
+// FFmpeg libavutil includes
+#include "libavutil/pixdesc.h"
+#include "libavutil/colorspace.h"
+
+// FFmpeg libavfilter includes
+#include "config.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "video.h"
+
+// Irdeto AVFilter command line include
+#include "vf_ott_cmd.h"
+
+/**
+********************************************************************************
+* @brief        Size of debug message buffer will be imported into WM library
+********************************************************************************
+*/
+#define IR_LOG_BUFFER_SIZE 4096
+
+/**
+********************************************************************************
+* @def          IR_WM_LIB
+* @brief        Default path to Irdeto OTT WM library
+********************************************************************************
+*/
+#define IR_WM_LIB "/usr/lib64/libottwm.so"
+
+/**
+********************************************************************************
+* @brief        Set Irdeto filter class name
+********************************************************************************
+*/
+AVFILTER_DEFINE_CLASS(irdeto);
+
+/**
+********************************************************************************
+* @brief        Performs conversion from AVPixelFormat to IR_OTTWM_PF
+* @param        [in] format     Pixel format defined by FFmpeg
+* @param        [in] ctx        Filter context, this parameter needed only for
+*                               print one line of LOG
+* @return       IR_OTTWM_PF converted from FFmpeg one 
+********************************************************************************
+*/
+static IR_OTTWM_PF ir_ottwm_convert_pf(const enum AVPixelFormat format,
+    AVFilterContext* const ctx)
+{
+    int result = 0;
+
+    switch(format)
+    {
+        case AV_PIX_FMT_YUV420P:
+            result = IR_OTTWM_PF_YUV420;
+        break;
+
+        case AV_PIX_FMT_YUV422P:
+            result = IR_OTTWM_PF_YUV422;
+        break;
+
+        case AV_PIX_FMT_YUV444P:
+            result = IR_OTTWM_PF_YUV444;
+        break;
+        
+        case AV_PIX_FMT_YUV420P10:
+            result = IR_OTTWM_PF_YUV420_10BIT;
+        break;
+
+        case AV_PIX_FMT_YUV422P10:
+            result = IR_OTTWM_PF_YUV422_10BIT;
+        break;
+
+        case AV_PIX_FMT_YUV444P10:
+            result = IR_OTTWM_PF_YUV444_10BIT;
+        break;
+        
+        default:
+            av_log(ctx, AV_LOG_ERROR, "Pixel format %s is not supported\n",
+                 av_get_pix_fmt_name(format));
+            result = -1;
+        break;
+    }
+
+    return result;
+}
+
+/**
+********************************************************************************
+* @brief    Parse TMID from string to tmid_t type
+* @param    [in,out]    ctx     Pointer to Filter Context
+* @todo     Write description on how TMID is represented
+* @return   IR_OTTWM_STATUS_OK on success, IR_OTTWM_STATUS_BADARG - otherwise
+********************************************************************************
+*/
+static IR_OTTWM_STATUS ir_ottwm_parse_tmid(AVFilterContext* const ctx)
+{
+    IR_OTTWM_STATUS result = IR_OTTWM_STATUS_BADARG;
+    struct ir_pf_context* context = ctx->priv;
+    char* endptr = NULL;
+    char buffer[19];
+
+    do
+    {
+        // 0x + 32 bytes for TMID value. \0 not encountered
+        if (34 != strlen(context->tmid))
+        {
+            av_log(ctx, AV_LOG_ERROR, "TMID should be 16 bytes long\n");
+            break;
+        }
+
+        if ('0' != context->tmid[0])
+        {
+            av_log(ctx, AV_LOG_ERROR, "TMID should begin from 0 symbol\n");
+            break;
+        }
+
+        if ('x' != context->tmid[1] && 'X' != context->tmid[1])
+        {
+            av_log(ctx, AV_LOG_ERROR,
+                "TMID should be in the format"
+                " 0xffffffffffffffffffffffffffffffff\n");
+            break;
+        }
+            
+        // prepare HSB of TMID to convert to uint64_t
+        memcpy(buffer, context->tmid, 18);
+        buffer[18] = '\0';
+
+        /**
+        ************************************************************************
+        * @warning  reset errno to zero - fix issue with strtoull() function
+        ************************************************************************
+        */
+        errno = 0;
+        context->tmid_num.sb[0] = strtoull(buffer, &endptr, 0);
+        if ('\0' != *endptr || 0 != errno)
+        {
+            av_log(ctx, AV_LOG_ERROR,
+                "Unrecognized symbol passed to TMID: %c(%x). Error: %d\n",
+                *endptr, *endptr, errno);
+            break;
+        }
+
+        // prepare LSB of TMID to convert to uint64_t
+        buffer[0] = '0';
+        buffer[1] = 'x';
+        memcpy(buffer + 2, context->tmid + 18, 16);
+        buffer[18] = '\0';
+        // reset errno to zero - fix issue with strtoull() function
+        errno = 0;
+        context->tmid_num.sb[1] = strtoull(buffer, &endptr, 0);        
+        if ('\0' != *endptr || 0 != errno)
+        {
+            av_log(ctx, AV_LOG_ERROR,
+                "Unrecognized symbol passed to TMID: %c(%x). Error: %d\n",
+                *endptr, *endptr, errno);
+            break;
+        }
+
+        av_log(ctx, AV_LOG_DEBUG, "Parsed TMID: 0x%llx%llx\n",
+            (long long unsigned int) context->tmid_num.sb[0],
+            (long long unsigned int) context->tmid_num.sb[1]);
+
+        result = IR_OTTWM_STATUS_OK;
+
+    } while(0);
+
+    return result;
+}
+
+/**
+********************************************************************************
+* @brief        Load Irdeto OTT WM library using dlopen and load all symbols
+*               to Filter context
+* @param        [in,out] ctx    Filter context
+* @return       IR_OTTWM_STATUS_OK on success, IR_OTTWM_STATUS_FAIL - oterwise
+********************************************************************************
+*/
+static IR_OTTWM_STATUS ir_ottwm_load_wm_library(AVFilterContext* const ctx)
+{
+    IR_OTTWM_STATUS result = IR_OTTWM_STATUS_FAIL;
+    struct ir_pf_context* context = ctx->priv;
+    char* lib = getenv("IR_WM_LIB");
+
+    do
+    {
+        if (lib == NULL)
+        {
+            lib = (char*) IR_WM_LIB;
+        }
+
+        av_log(ctx, AV_LOG_DEBUG, "Watermarking library %s will be used\n",
+            lib);
+
+        context->wm_handle = dlopen(lib, RTLD_NOW);
+        if (NULL == context->wm_handle)
+        {
+            av_log(ctx, AV_LOG_ERROR, "Can't load WM library %s. Error: %s\n",
+                lib, dlerror());
+            break;
+        }
+
+        // Load functions
+        context->wm_init = (f_ir_init) dlsym(context->wm_handle,
+            "ir_ottwm_init");
+        if (NULL == context->wm_init)
+        {
+            av_log(ctx, AV_LOG_ERROR,
+                "Can't load ir_ottwm_init function. Error: %s\n", dlerror());
+            break;
+        }
+
+        context->wm_embed = (f_ir_embed) dlsym(context->wm_handle,
+            "ir_ottwm_embed");
+        if (NULL == context->wm_embed)
+        {
+            av_log(ctx, AV_LOG_ERROR,
+                "Can't load ir_ottwm_init function. Error: %s\n", dlerror());
+            break;
+        }
+
+        context->wm_uninit = (f_ir_uninit) dlsym(context->wm_handle,
+            "ir_ottwm_uninit");
+        if (NULL == context->wm_uninit)
+        {
+            av_log(ctx, AV_LOG_ERROR,
+                "Can't load ir_ottwm_uninit function. Error: %s\n", dlerror());
+            break;
+        }
+
+        context->wm_version = (f_ir_version) dlsym(context->wm_handle,
+            "ir_ottwm_get_version");
+        if (NULL == context->wm_version)
+        {
+            av_log(ctx, AV_LOG_ERROR,
+                "Can't load ir_ottwm_get_version function. Error: %s\n",
+                dlerror());
+            break;
+        }
+
+        result = IR_OTTWM_STATUS_OK;
+    } while(0);
+
+    return result;
+}
+
+/**
+********************************************************************************
+* @brief        Print configuration passed to FFmpeg filter
+* @param        [in] ctx    Filter context
+* @return       void
+********************************************************************************
+*/
+static void ir_print_config(AVFilterContext* const ctx)
+{
+    struct ir_pf_context* context = ctx->priv;
+    av_log(ctx, AV_LOG_INFO,
+            "Irdeto WM filter configuration\n"
+            "%s\n"
+            "\tWatermarking period: %lu %s\n"
+            "\tWatermark frame range: [%lu, %lu]\n"
+            "\tWatermark symbol range: [%u, %u]\n"
+            "\tLines excluded from watermarking: %u at top, %u at bottom\n"
+            "\tOperator: %u\n"
+            "\tTMID: %s (%llx%llx)\n"
+            "\tWatermarking Post-Filter: %s (%d)\n"
+            "\tGOP structure description file: %s(%d bytes)\n",
+            context->wm_version(context->embedder),
+            context->config.wmtime ? context->config.wmtime : context->config.wmframes,
+            context->config.wmtime ? "milliseconds" : "frames",
+            context->config.firstframe, context->config.lastframe,
+            context->config.firstbit, context->config.lastbit,
+            context->config.lbtop, context->config.lbbottom,
+            context->config.id,
+            context->tmid,
+            (unsigned long long int) context->tmid_num.sb[0],
+            (unsigned long long int) context->tmid_num.sb[1],
+            context->config.pfe ? "Gaussian" : "N/A", context->config.pfe,
+            context->gopstr, context->config.gs_size);
+}
+
+/**
+********************************************************************************
+* @brief        Read GOP structure from the file to the buffer
+* @param        [in] ctx	Pointer to the AVFilterContext structure
+* @return       IR_OTTWM_STATUS_OK on success,
+*               IR_OTTWM_STATUS_FAIL - otherwise
+********************************************************************************
+*/
+static IR_OTTWM_STATUS ir_ottwm_read_gopstr(AVFilterContext* const ctx)
+{
+    struct ir_pf_context* context = ctx->priv;
+    FILE* f = NULL;
+    char* temp = NULL;
+    char* p = NULL;
+    char* buffer = NULL;
+    long size = 0;
+    int i;
+    size_t tmp;
+    IR_OTTWM_STATUS result = IR_OTTWM_STATUS_FAIL;
+
+    do
+    {
+        f = fopen(context->gopstr, "rb");
+        if (NULL == f)
+        {
+        	av_log(ctx, AV_LOG_ERROR, "Can't open %s file\n", context->gopstr);
+            break;
+        }
+
+        fseek(f, 0, SEEK_END);
+        size = ftell(f);
+        if (0 > size)
+        {
+        	av_log(ctx, AV_LOG_ERROR, "Can't estimate buffer size for %s "
+        			"file\n", context->gopstr);
+            fclose(f);
+            break;
+        }
+
+        rewind(f);
+
+        context->config.gop_str  = (char*)malloc(size + 1);   // Placeholder for '\0'
+        if (NULL == context->config.gop_str)
+        {
+        	av_log(ctx, AV_LOG_ERROR, "Can't allocate buffer of size %ld for "
+        			"%s file\n", size, context->gopstr);
+            fclose(f);
+            break;
+        }
+
+        tmp = fread(context->config.gop_str, 1, size, f);
+        if (tmp != (size_t)size)
+        {
+        	av_log(ctx, AV_LOG_ERROR, "Can't read file %s (%ld:%ld). Error: %d "
+        			"(EOF: %d)\n", context->gopstr, tmp, size, ferror(f),
+					feof(f));
+            fclose(f);
+            break;
+        }
+
+        context->config.gop_str[size] = '\0';
+        context->config.gs_size = (size_t)(size + 1);
+
+        fclose(f);
+
+        result = IR_OTTWM_STATUS_OK;
+    } while(0);
+
+    return result;
+}
+
+/**
+********************************************************************************
+* @brief    Irdeto FFmpeg video filter initialization routine
+* @param    [in] ctx    Pointer to the Filter context
+* @return   0 on success, AVERROR - otherwise
+********************************************************************************
+*/
+static av_cold int vf_ottwm_init(AVFilterContext* const ctx)
+{
+    IR_OTTWM_STATUS result = IR_OTTWM_STATUS_BADARG;
+    struct ir_pf_context* context = ctx->priv;
+    int sys = 0;
+
+    do
+    {
+        if (NULL == context->tmid)
+        {
+            sys = EINVAL;
+            break;
+        }
+
+        result = ir_ottwm_parse_tmid(ctx);
+        if (IR_OTTWM_STATUS_OK != result)
+        {
+            sys = EINVAL;
+            break;
+        }
+
+        result = ir_ottwm_read_gopstr(ctx);
+        if(IR_OTTWM_STATUS_OK != result){
+            sys = EINVAL;
+            break;
+        }
+
+        result = ir_ottwm_load_wm_library(ctx);
+        if (IR_OTTWM_STATUS_OK != result)
+        {
+            sys = ENOENT;
+            break;
+        }
+
+        context->log_buffer = (char*) malloc(IR_LOG_BUFFER_SIZE);
+        if (NULL == context->log_buffer)
+        {
+            av_log(ctx, AV_LOG_ERROR,
+                "Can't allocate memory for debug log buffer");
+            sys = EINVAL;
+            break;
+        }
+
+        context->state = VF_STATE_UNINITIALIZED;
+
+        av_log(ctx, AV_LOG_INFO,
+            "Irdeto FFmpeg Video Filter  %d.%d.%d-%d initialized\n",
+            VF_OTT_VERSION_MAJOR, VF_OTT_VERSION_MIDDLE, VF_OTT_VERSION_MINOR,
+            VF_OTT_RELEASE);
+
+    } while(0);
+
+    return AVERROR(sys);
+}
+
+/**
+********************************************************************************
+* @brief        Does post initialization of the OTT embedding library when all
+*               stream characteristics known
+* @param        [in] inlink     Pointer to the input stream information
+* @param        [in] frame      Pointer to the FFmpeg frame
+* @return       IR_OTTWM_STATUS_OK on success, IR_OTTWM_STATUS_FAIL - otherwise
+********************************************************************************
+*/
+static IR_OTTWM_STATUS vf_ottwm_postinit(AVFilterLink* const inlink,
+    AVFrame* const frame)
+{
+    IR_OTTWM_STATUS result          = IR_OTTWM_STATUS_FAIL;
+    AVFilterContext* filter         = (AVFilterContext*) inlink->dst;
+    struct ir_pf_context* context   = (struct ir_pf_context*) filter->priv;
+
+    do
+    {
+        if (VF_STATE_INITIALIZED == context->state) // Early exit when done
+        {
+            result = IR_OTTWM_STATUS_OK;
+            break;
+        }
+        ir_print_config(filter);
+
+        context->config.width       = frame->width;
+        context->config.height      = frame->height;
+        context->config.linesize    = frame->linesize[0];
+        context->config.fps         = inlink->frame_rate.num
+                                        / (float) inlink->frame_rate.den;
+        context->config.log_buffer  = context->log_buffer;
+        context->config.lb_size     = IR_LOG_BUFFER_SIZE;
+        context->config.pf          = ir_ottwm_convert_pf(inlink->format,
+                                        filter);
+
+        result = context->wm_init(&context->config, &context->embedder);
+        if (IR_OTTWM_STATUS_OK != result)
+        {
+            av_log(filter, AV_LOG_ERROR, "%s", context->log_buffer);
+            break;
+        }
+        av_log(filter, AV_LOG_DEBUG, "%s",  context->log_buffer);
+
+        context->state = VF_STATE_INITIALIZED;
+        result = IR_OTTWM_STATUS_OK;
+
+    } while(0);
+
+    return result;
+}
+
+/**
+********************************************************************************
+* @brief        Process single frame
+* @note         FFmpeg AVFrame quick specification:
+*               int line_size_U = frame->linesize[1];
+*               int line_size_V = frame->linesize[2];
+*               uint8_t  *U     = frame->data[1];
+*               uint8_t  *V     = frame->data[2];
+*               uint32_t pict_size_Y = height*line_size_Y;
+*               uint32_t pict_size_U = (height>>irdeto->vsub)*line_size_U;
+*               uint32_t pict_size_V = (height>>irdeto->vsub)*line_size_V;
+*               inlink->w
+*               inlink->h
+*               inlink->sample_aspect_ratio
+*               inlink->frame_count (starts from zero)
+*               frame->pts == AV_NOPTS_VALUE ? 
+*                   NAN : frame->pts * av_q2d(inlink->time_base);
+*               frame->pict_type;
+*               AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(inlink->format);
+*               irdeto->hsub = desc->log2_chroma_w;
+*               irdeto->vsub = desc->log2_chroma_h;
+* @return       IR_OTTWM_STATUS_OK on success, 
+*               IR_OTTWM_STATUS_BADGOP if input GOP structure file does not 
+*               satisfy special requirements, IR_OTTWM_STATUS_FAIL - otherwise
+********************************************************************************
+*/
+static IR_OTTWM_STATUS vf_ottwm_process_frame(AVFilterLink* const inlink, 
+    AVFrame* const frame)
+{
+    IR_OTTWM_STATUS result = IR_OTTWM_STATUS_FAIL;
+    AVFilterContext* filter = (AVFilterContext*) inlink->dst;
+    struct ir_pf_context* context = (struct ir_pf_context*) filter->priv;
+    struct ir_ottwm_ec emb;
+    
+    do
+    {
+        av_frame_make_writable(frame);
+        emb.pic = frame->data[0];
+
+        /**
+        ************************************************************************
+        * @note     In case WM embedding library will be used outside of FFmpeg
+        *           caller is responsible to make proper PTS
+        ************************************************************************
+        */
+        emb.pts = frame->pts * av_q2d(inlink->time_base) * 1000;
+        result = context->wm_embed(context->embedder, &emb);
+        if (IR_OTTWM_STATUS_OK != result)
+        {
+            av_log(filter, AV_LOG_ERROR,
+                "Can't embed watermark into a frame. Error: %d\n", result);
+            break;
+        }
+
+        result = IR_OTTWM_STATUS_OK;
+
+    } while(0);
+
+    return result;
+}
+
+/**
+********************************************************************************
+* @brief    This function called for every frame in the stream that will be
+*           filtered
+* @param    [in] inlink Pointer to input link of the AVFilter
+* @param    [in] frame  Pointer to Video frame decoded by FFmpeg
+* @return   0 on success, non-zero - otherwise
+********************************************************************************
+*/
+static int ff_ottwm_filter_frame(AVFilterLink* const inlink,
+    AVFrame* const frame)
+{
+    int sys = 0;
+    IR_OTTWM_STATUS result = IR_OTTWM_STATUS_BADARG;
+    AVFilterContext* ctx = (AVFilterContext*) inlink->dst;
+    
+    do
+    {
+        result = vf_ottwm_postinit(inlink, frame);
+        if (IR_OTTWM_STATUS_OK != result)
+        {
+            sys = EPERM;
+            break;
+        }
+
+        result = vf_ottwm_process_frame(inlink, frame);
+        if (IR_OTTWM_STATUS_OK != result)
+        {
+            sys = EPERM;
+            break;
+        }
+
+        sys = ff_filter_frame(ctx->outputs[0], frame);
+        
+    } while(0);
+
+    return AVERROR(sys);
+}
+
+/**
+********************************************************************************
+* @brief    Irdeto FFmpeg video filter uninitialization
+* @param    [in] ctx    Pointer to AVFilter context structure
+* @return   void
+********************************************************************************
+*/
+static av_cold void vf_ottwm_uninit(AVFilterContext* const ctx)
+{
+    struct ir_pf_context* context = ctx->priv;
+
+    free(context->config.gop_str);
+    if (context->wm_handle)
+    {
+        dlclose(context->wm_handle);
+    }
+
+    av_log(ctx, AV_LOG_INFO, "Irdeto FFmpeg Video filter was uninitialized");
+}
+
+/**
+********************************************************************************
+* @brief    This function called when the filter must be reinitialized
+* @param    [in] ctx    Pointer to AVFilter context
+* @param    [in] cmd    Command should be executed
+* @param    [in] arg    Argument (Unused)
+* @param    [in] res    Resource (Unused)
+* @param    [in] size   Lenght of resource
+* @param    [in] flags  Options
+* @return   0 on success, AVERROR - otherwise
+********************************************************************************
+ */
+static int vf_ottwm_pc(AVFilterContext* const ctx, const char* const cmd,
+    const char* const arg, char* const res, int size, int flags)
+{
+    int result = 0;
+
+    do
+    {
+        result = strcmp(cmd, "reinit");
+        if (0 != result)
+        {
+            result = AVERROR(ENOSYS);
+            break;
+        }
+
+        vf_ottwm_uninit(ctx);
+        result = vf_ottwm_init(ctx);
+    } while(0);
+
+    return result;
+}
+
+/**
+********************************************************************************
+* @brief    Connector for the filter inputs
+********************************************************************************
+*/
+static const AVFilterPad ff_vf_irdeto_inputs[] =
+{
+    {
+        .name             = "default",
+        .type             = AVMEDIA_TYPE_VIDEO,
+        .get_video_buffer = ff_null_get_video_buffer,
+        .filter_frame     = ff_ottwm_filter_frame,
+        .config_props     = NULL,
+        .needs_writable   = 1,
+    },
+    { NULL }
+};
+
+/**
+********************************************************************************
+* @brief    Connector for the filter outputs
+********************************************************************************
+*/
+static const AVFilterPad ff_vf_irdeto_outputs[] =
+{
+    {
+        .name = "default",
+        .type = AVMEDIA_TYPE_VIDEO,
+    },
+    { NULL }
+};
+
+/**
+********************************************************************************
+* @brief    List pixel formats plugin will be able to watermark
+* @param    [in] ctx    Pointer to Filter context
+* @note     This function will be called asyncronously by FFmpeg engine
+* @return   Value returned by ff_set_common_formats
+********************************************************************************
+*/
+static int ir_ottwm_register_formats(AVFilterContext* const ctx)
+{
+    enum AVPixelFormat pix_fmts[] =
+    {
+        AV_PIX_FMT_YUV420P10,
+        AV_PIX_FMT_YUV422P10,
+        AV_PIX_FMT_YUV444P10,
+        AV_PIX_FMT_YUV420P,
+        AV_PIX_FMT_YUV422P,
+        AV_PIX_FMT_YUV444P,
+        AV_PIX_FMT_NONE
+    };
+    return ff_set_common_formats(ctx, ff_make_format_list(pix_fmts));
+}
+
+/**
+********************************************************************************
+* @brief    Irdeto OTT WM Filter definition
+********************************************************************************
+*/
+AVFilter ff_vf_irdeto =
+{
+    .name            = "irdeto",
+    .description     = NULL_IF_CONFIG_SMALL("Irdeto custom FFmpeg filter"),
+    .priv_size       = sizeof(struct ir_pf_context),
+    .priv_class      = &irdeto_class,
+    .init            = vf_ottwm_init,
+    .uninit          = vf_ottwm_uninit,
+    .query_formats   = ir_ottwm_register_formats,
+    .inputs          = ff_vf_irdeto_inputs,
+    .outputs         = ff_vf_irdeto_outputs,
+    .process_command = vf_ottwm_pc,
+};
diff --git a/source/libavfilter/vf_rgb_cnt.c b/source/libavfilter/vf_rgb_cnt.c
new file mode 100644
index 0000000..c211a42
--- /dev/null
+++ b/source/libavfilter/vf_rgb_cnt.c
@@ -0,0 +1,460 @@
+/*
+* Copyright (c) 2013-2016 Irdeto B.V.
+*
+* This file is part of FFmpeg.
+*
+* FFmpeg is free software; you can redistribute it and/or
+* modify it under the terms of the GNU Lesser General Public
+* License as published by the Free Software Foundation; either
+* version 2.1 of the License, or (at your option) any later version.
+*
+* FFmpeg is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+* Lesser General Public License for more details.
+*
+* You should have received a copy of the GNU Lesser General Public
+* License along with FFmpeg; if not, write to the Free Software
+* Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+*/
+
+// Global system includes
+#include <unistd.h>
+#include <dlfcn.h>
+#include <stdio.h>
+#include <inttypes.h>
+
+// FFmpeg libavutil includes
+#include "libavutil/pixdesc.h"
+#include "libavutil/colorspace.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/opt.h"
+
+// FFmpeg libswscale includes
+#include "libswscale/swscale.h"
+
+// FFmpeg libavfilter includes
+#include "config.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "video.h"
+
+/**
+********************************************************************************
+* @enum         VF_STATE
+* @brief        Video filter states representation
+********************************************************************************
+*/
+typedef enum
+{
+    VF_STATE_UNINITIALIZED  = 0,    ///< Video filter uninitialized
+    VF_STATE_INITIALIZED    = 1     ///< Video filter initialized
+} VF_STATE;
+
+/**
+********************************************************************************
+* @enum         COLOR
+* @brief        RGB color space representation
+********************************************************************************
+*/
+typedef enum
+{
+    RED      = 0,    ///< R
+    GREEN    = 1,    ///< G
+    BLUE     = 2,    ///< B
+    NONE     = 3     ///< Uninit value
+} COLOR;
+
+static const char* color_name[4] = 
+{
+    "Red",
+    "Green",
+    "Blue",
+    "None"
+};
+
+/**
+********************************************************************************
+* @enum         IR_RGBCNT_STATUS
+* @brief        OTT watermarking library error codes
+********************************************************************************
+*/
+typedef enum
+{
+    IR_RGBCNT_STATUS_OK      = 0,    ///< OK
+    IR_RGBCNT_STATUS_NI      = 1,    ///< Not implemented
+    IR_RGBCNT_STATUS_BADARG  = 2,    ///< Bad arguments passed
+    IR_RGBCNT_STATUS_LIF     = 3,    ///< Failed to initialize WM library
+    IR_RGBCNT_STATUS_OIF     = 4,    ///< Failed to set operator ID
+    IR_RGBCNT_STATUS_FWS     = 5,    ///< TBD
+    IR_RGBCNT_STATUS_FPF     = 6,    ///< Failed to set frame properties
+    IR_RGBCNT_STATUS_SKIP    = 7,
+    IR_RGBCNT_STATUS_FAIL    = -1
+
+} IR_RGBCNT_STATUS;
+
+typedef struct ir_rgb_context
+{
+    int            width;
+    int            height;
+    int            linesize;
+    int            detph;
+    float          fps;
+
+    uint8_t*       rgb_data;
+    size_t         rgb_size;
+    AVFrame*       pFrameRGB;
+
+    VF_STATE       state;
+    COLOR          color;
+    COLOR          prev_color;
+    int            red_cnt;
+    int            green_cnt;
+    int            blue_cnt;
+} RgbcntContext;
+
+/**
+********************************************************************************
+* @brief    Irdeto FFmpeg rgb counter initialization routine
+* @param    [in] ctx    Pointer to the Filter context
+* @return   0 on success, AVERROR - otherwise
+********************************************************************************
+*/
+static av_cold int vf_rgbcnt_init(AVFilterContext* const ctx)
+{
+    int sys = 0;
+    struct ir_rgb_context* context = ctx->priv;
+
+    context->state = VF_STATE_UNINITIALIZED;
+
+    return AVERROR(sys);
+}
+
+/**
+********************************************************************************
+* @brief        Does post initialization of the rgb counter when all
+*               stream characteristics known
+* @param        [in] inlink     Pointer to the input stream information
+* @param        [in] frame      Pointer to the FFmpeg frame
+* @return       IR_OTTWM_STATUS_OK on success, IR_OTTWM_STATUS_FAIL - otherwise
+********************************************************************************
+*/
+static IR_RGBCNT_STATUS vf_rgbcnt_postinit(AVFilterLink* const inlink,
+    AVFrame* const frame)
+{
+    AVFilterContext* filter = (AVFilterContext*) inlink->dst;
+    struct ir_rgb_context* context = (struct ir_rgb_context*) filter->priv;
+    IR_RGBCNT_STATUS result = IR_RGBCNT_STATUS_FAIL;
+    int rc = -1;
+
+    do
+    {
+        if (context->state == VF_STATE_INITIALIZED)
+        {
+            result = IR_RGBCNT_STATUS_OK;
+            break;
+        }
+        context->prev_color = NONE;
+        context->color = NONE;
+        context->red_cnt = 0;
+        context->green_cnt = 0;
+        context->blue_cnt = 0;
+
+        context->width = frame->width;
+        context->height = frame->height;
+        context->detph = (frame->width * 2 == frame->linesize[0]) ? 10 : 8;
+        context->linesize = (context->detph == 10) \
+                            ? frame->width * 2 : frame->width;
+        context->fps = inlink->frame_rate.num / (float) inlink->frame_rate.den;
+
+        context->rgb_size = av_image_get_buffer_size(AV_PIX_FMT_RGB24, \
+                                context->width, context->height, 1);
+        context->rgb_data = (uint8_t*)malloc(context->rgb_size);
+        if (context->rgb_data == NULL)
+        {
+            av_log(filter, AV_LOG_ERROR, "Can't allocate memory for RGB\n");
+            break;
+        }
+
+        context->pFrameRGB = av_frame_alloc();
+        if (context->pFrameRGB == NULL)
+        {
+            av_log(filter, AV_LOG_ERROR, "Can't allocate frame\n");
+            break;
+        }
+        rc = av_image_fill_arrays(context->pFrameRGB->data, \
+            context->pFrameRGB->linesize, context->rgb_data, AV_PIX_FMT_RGB24, \
+            context->width, context->height, 1);
+        if (rc < 0)
+        {
+            av_log(filter, AV_LOG_ERROR, "Error when filling arrays\n");
+            break;
+        }
+
+        context->state = VF_STATE_INITIALIZED;
+        result = IR_RGBCNT_STATUS_OK;
+
+    } while(0);
+
+    return result;
+}
+
+/**
+********************************************************************************
+* @name     Irdeto FFmpeg rgb counter get color routine
+* @brief    This functions decides whether the current frame is a red, green or 
+*           blue frame. This video filter is intended to be used with test 
+*           videos generated with command: ffmpeg -f lavi -i color=color=[red, 
+            green, blue] -t Time test_stream.mp4
+* @param    [in] ctx    Pointer to ir_rgb_context
+* @return   void
+********************************************************************************
+*/
+static void vf_get_color(struct ir_rgb_context* context)
+{
+    int i;
+    int red_pel = 0;
+    int green_pel = 0;
+    int blue_pel = 0;
+
+    for (i = 0; i < context->width * context->height * 3; i+=3)
+    {
+        /*  Image with green and blue channels equal to 0 and red channel 
+            greater than 230 is considered as a red frame for testing  */
+        if (context->pFrameRGB->data[0][i] >= 230 && \
+            context->pFrameRGB->data[0][i+1] == 0 && \
+            context->pFrameRGB->data[0][i+2] == 0)
+        {
+            red_pel++;
+        }
+        /*  Image with red and blue channels equal to 0 and green channel 
+            greater than 100 is considered as a green frame for testing  */
+        if (context->pFrameRGB->data[0][i] == 0 && \
+            context->pFrameRGB->data[0][i+1] >= 100 && \
+            context->pFrameRGB->data[0][i+2] == 0)
+        {
+            green_pel++;
+        }
+        /*  Image with red and green channels equal to 0 and blue channel 
+            greater than 230 is considered as a blue frame for testing  */
+        if (context->pFrameRGB->data[0][i] == 0 && \
+            context->pFrameRGB->data[0][i+1] == 0 && \
+            context->pFrameRGB->data[0][i+2] >= 230)
+        {
+            blue_pel++;
+        }
+    }
+
+    if (red_pel == context->width * context->height)
+    {
+        context->prev_color = context->color;
+        context->color = RED;
+        context->red_cnt++;
+    }
+    if (green_pel == context->width * context->height)
+    {
+        context->prev_color = context->color;
+        context->color = GREEN;
+        context->green_cnt++;
+    }
+    if (blue_pel == context->width * context->height)
+    {
+        context->prev_color = context->color;
+        context->color = BLUE;
+        context->blue_cnt++;
+    }
+}
+
+/**
+********************************************************************************
+* @brief        Process single frame
+* @note         FFmpeg AVFrame quick specification:
+*               int line_size_U = frame->linesize[1];
+*               int line_size_V = frame->linesize[2];
+*               uint8_t  *U     = frame->data[1];
+*               uint8_t  *V     = frame->data[2];
+*               uint32_t pict_size_Y = height*line_size_Y;
+*               uint32_t pict_size_U = (height>>irdeto->vsub)*line_size_U;
+*               uint32_t pict_size_V = (height>>irdeto->vsub)*line_size_V;
+*               inlink->w
+*               inlink->h
+*               inlink->sample_aspect_ratio
+*               inlink->frame_count
+*               frame->pts == AV_NOPTS_VALUE ? 
+*                   NAN : frame->pts * av_q2d(inlink->time_base);
+*               frame->pict_type;
+*               AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(inlink->format);
+*               irdeto->hsub = desc->log2_chroma_w;
+*               irdeto->vsub = desc->log2_chroma_h;
+* @return       IR_OTTWM_STATUS_OK on success, IR_OTTWM_STATUS_FAIL - otherwise
+********************************************************************************
+*/
+static IR_RGBCNT_STATUS vf_rgbcnt_process_frame(AVFilterLink* const inlink,
+    AVFrame* const frame)
+{
+    IR_RGBCNT_STATUS result = IR_RGBCNT_STATUS_FAIL;
+    AVFilterContext* filter = (AVFilterContext*) inlink->dst;
+    struct ir_rgb_context* context = (struct ir_rgb_context*) filter->priv;
+
+    do
+    {
+        /*  Scaling function that converts YUV frame into RGB representation  
+            YUV data cannot be used to determine whether frame is red, blue or 
+            green, as red and green frame has same Y value  */
+        struct SwsContext* sc;
+        sc = sws_getContext(context->width, context->height, frame->format, \
+                            context->width, context->height, AV_PIX_FMT_RGB24, \
+                            SWS_BICUBIC, NULL, NULL, NULL);
+        sws_scale(sc, (const uint8_t* const*)frame->data, frame->linesize, \
+                    0, frame->height, context->pFrameRGB->data, \
+                    context->pFrameRGB->linesize);
+
+        vf_get_color(context);
+        if (context->prev_color != context->color)
+        {
+            av_log(filter, AV_LOG_INFO, "Switch from color %s to color %s"
+                    " at frame number %"PRId64"\n", color_name[context->prev_color], 
+                    color_name[context->color], inlink->frame_count);
+        }
+
+        result = IR_RGBCNT_STATUS_OK;
+
+    } while(0);
+
+    return result;
+}
+/**
+********************************************************************************
+* @brief    This function called for every frame in the stream that will be
+*           filtered
+* @param    [in] inlink Pointer to input link of the AVFilter
+* @param    [in] frame  Pointer to Video frame decoded by FFmpeg
+* @return   0 on success, non-zero - otherwise
+********************************************************************************
+*/
+static int ff_rgbcnt_filter_frame(AVFilterLink* const inlink,
+    AVFrame* const frame)
+{
+    int sys = 0;
+    IR_RGBCNT_STATUS result = IR_RGBCNT_STATUS_BADARG;
+    AVFilterContext* ctx = (AVFilterContext*) inlink->dst;
+    
+    do
+    {
+        result = vf_rgbcnt_postinit(inlink, frame);
+        if (IR_RGBCNT_STATUS_OK != result)
+        {
+            sys = EPERM;
+            break;
+        }
+
+        result = vf_rgbcnt_process_frame(inlink, frame);
+        if (IR_RGBCNT_STATUS_OK != result)
+        {
+            sys = EPERM;
+            break;
+        }
+
+        sys = ff_filter_frame(ctx->outputs[0], frame);
+        
+    } while(0);
+
+    return AVERROR(sys);
+}
+
+/**
+********************************************************************************
+* @brief    Irdeto FFmpeg video filter uninitialization
+* @param    [in] ctx    Pointer to AVFilter context structure
+* @return   void
+********************************************************************************
+*/
+static av_cold void vf_rgbcnt_uninit(AVFilterContext* const ctx)
+{
+    struct ir_rgb_context* context = (struct ir_rgb_context*) ctx->priv;
+    free(context->rgb_data);
+    av_frame_free(&context->pFrameRGB);
+
+    av_log(ctx, AV_LOG_INFO, "red frame count: %d\n", context->red_cnt);
+    av_log(ctx, AV_LOG_INFO, "green frame count: %d\n", context->green_cnt);
+    av_log(ctx, AV_LOG_INFO, "blue frame count: %d\n", context->blue_cnt);
+    av_log(ctx, AV_LOG_INFO, "Irdeto rgb counter uninitialized.\n");
+}
+
+/**
+********************************************************************************
+* @brief    List pixel formats plugin will be able to count rgb frames
+* @param    [in] ctx    Pointer to Filter context
+* @note     This function will be called asyncronously by FFmpeg engine
+* @return   0
+********************************************************************************
+*/
+static int ir_rgbcnt_register_formats(AVFilterContext* const ctx)
+{
+    static const enum AVPixelFormat pix_fmts[] =
+    {
+        AV_PIX_FMT_YUV420P10,
+        AV_PIX_FMT_YUV422P10,
+        AV_PIX_FMT_YUV444P10,
+        AV_PIX_FMT_YUV420P,
+        AV_PIX_FMT_YUV422P,
+        AV_PIX_FMT_YUV444P,
+        AV_PIX_FMT_NONE
+    };
+
+    AVFilterFormats *fmts_list = ff_make_format_list(pix_fmts);
+    if (!fmts_list)
+    {
+        return AVERROR(ENOMEM);
+    }
+    return ff_set_common_formats(ctx, fmts_list);
+}
+
+/**
+********************************************************************************
+* @brief    Connector for the filter inputs
+********************************************************************************
+*/
+static const AVFilterPad ff_vf_rgbcnt_inputs[] =
+{
+    {
+        .name             = "default",
+        .type             = AVMEDIA_TYPE_VIDEO,
+        .get_video_buffer = ff_null_get_video_buffer,
+        .filter_frame     = ff_rgbcnt_filter_frame,
+        .config_props     = NULL,
+    },
+    { NULL }
+};
+
+/**
+********************************************************************************
+* @brief    Connector for the filter outputs
+********************************************************************************
+*/
+static const AVFilterPad ff_vf_rgbcnt_outputs[] =
+{
+    {
+        .name = "default",
+        .type = AVMEDIA_TYPE_VIDEO,
+    },
+    { NULL }
+};
+
+/**
+********************************************************************************
+* @brief    Irdeto RGB counter definition
+********************************************************************************
+*/
+AVFilter ff_vf_rgbcnt =
+{
+    .name            = "rgbcnt",
+    .description     = NULL_IF_CONFIG_SMALL("Irdeto custom rgb counter."),
+    .priv_size       = sizeof(struct ir_rgb_context),
+    .init            = vf_rgbcnt_init,
+    .uninit          = vf_rgbcnt_uninit,
+    .query_formats   = ir_rgbcnt_register_formats,
+    .inputs          = ff_vf_rgbcnt_inputs,
+    .outputs         = ff_vf_rgbcnt_outputs,
+};
diff --git a/source/libavformat/mov.c b/source/libavformat/mov.c
index 7266fd0..6541ecf 100644
--- a/source/libavformat/mov.c
+++ b/source/libavformat/mov.c
@@ -1396,6 +1396,28 @@ static int mov_read_fiel(MOVContext *c, AVIOContext *pb, MOVAtom atom)
     return 0;
 }
 
+/**
+********************************************************************************
+* @author       Fabian van der Werf (fabian.vanderwerf@irdeto.com)
+* @brief        Reading of ProRes clap atom
+* @param        [in] c      MOV context
+* @param        [in] pb     Input context
+* @param        [in]atom    MOV atom
+* @retrn        0 on succes, error code - otherwise
+********************************************************************************
+*/
+static int mov_read_clap(MOVContext *c, AVIOContext *pb, MOVAtom atom)
+{
+    AVStream *st;
+ 
+    if (c->fc->nb_streams < 1)
+        return 0;
+    st = c->fc->streams[c->fc->nb_streams-1];
+ 
+    avio_skip(pb, 8*4);
+    return av_dict_set_int(&(st->metadata), "mov.clap", 1, 0);
+}
+
 static int mov_realloc_extradata(AVCodecParameters *par, MOVAtom atom)
 {
     int err = 0;
@@ -4320,6 +4342,7 @@ static const MOVParseTableEntry mov_default_parse_table[] = {
 { MKTAG('A','R','E','S'), mov_read_ares },
 { MKTAG('a','v','s','s'), mov_read_avss },
 { MKTAG('c','h','p','l'), mov_read_chpl },
+{ MKTAG('c','l','a','p'), mov_read_clap },  ///< Add CLAP parsing
 { MKTAG('c','o','6','4'), mov_read_stco },
 { MKTAG('c','o','l','r'), mov_read_colr },
 { MKTAG('c','t','t','s'), mov_read_ctts }, /* composition time to sample */
diff --git a/source/libavformat/mxf.h b/source/libavformat/mxf.h
index f3db1f9..d1348f5 100644
--- a/source/libavformat/mxf.h
+++ b/source/libavformat/mxf.h
@@ -62,6 +62,14 @@ typedef struct KLVPacket {
     UID key;
     int64_t offset;
     uint64_t length;
+    
+    /**
+    ****************************************************************************
+    * @author   Michael Verberne (michael.verberne@irdeto.com)
+    * @date     Jul 30, 2015
+    ****************************************************************************
+    */
+    uint64_t ber_size;
 } KLVPacket;
 
 typedef struct MXFCodecUL {
diff --git a/source/libavformat/mxfdec.c b/source/libavformat/mxfdec.c
index 0affca9..9f4969a 100644
--- a/source/libavformat/mxfdec.c
+++ b/source/libavformat/mxfdec.c
@@ -337,6 +337,29 @@ static void mxf_free_metadataset(MXFMetadataSet **ctx, int freectx)
     av_freep(ctx);
 }
 
+/**
+********************************************************************************
+* @author   Michael Verberne (michael.verberne@irdeto.com)
+* @date     Jul 30, 2015
+********************************************************************************
+*/
+static int64_t klv_decode_ber_length_ex(AVIOContext *pb, int64_t *ber_size)
+{
+    uint64_t size = avio_r8(pb);
+    *ber_size = 1;
+    if (size & 0x80) { /* long form */
+        int bytes_num = size & 0x7f;
+        /* SMPTE 379M 5.3.4 guarantee that bytes_num must not exceed 8 bytes */
+        if (bytes_num > 8)
+            return AVERROR_INVALIDDATA;
+        *ber_size += bytes_num;
+        size = 0;
+        while (bytes_num--)
+            size = size << 8 | avio_r8(pb);
+    }
+    return size;
+}
+
 static int64_t klv_decode_ber_length(AVIOContext *pb)
 {
     uint64_t size = avio_r8(pb);
@@ -372,7 +395,16 @@ static int klv_read_packet(KLVPacket *klv, AVIOContext *pb)
     klv->offset = avio_tell(pb) - 4;
     memcpy(klv->key, mxf_klv_key, 4);
     avio_read(pb, klv->key + 4, 12);
-    klv->length = klv_decode_ber_length(pb);
+
+    //klv->length = klv_decode_ber_length(pb);
+    
+    /**
+    ****************************************************************************
+    * @author   Michael Verberne (michael.verberne@irdeto.com)
+    * @date     Jul 30, 2015
+    ****************************************************************************
+    */
+    klv->length = klv_decode_ber_length_ex(pb, &klv->ber_size);
     return klv->length == -1 ? -1 : 0;
 }
 
@@ -3006,6 +3038,14 @@ static int mxf_read_packet_old(AVFormatContext *s, AVPacket *pkt)
             pkt->stream_index = index;
             pkt->pos = klv.offset;
 
+            /**
+            ********************************************************************
+            * @author   Michael Verberne (michael.verberne@irdeto.com)
+            * @date     Jul 30, 2015
+            ********************************************************************
+            */
+            pkt->hdr_size = 16 + klv.ber_size;
+
             par = st->codecpar;
 
             if (par->codec_type == AVMEDIA_TYPE_VIDEO && next_ofs >= 0) {
diff --git a/source/libavformat/utils.c b/source/libavformat/utils.c
index d2a709c..bae4203 100644
--- a/source/libavformat/utils.c
+++ b/source/libavformat/utils.c
@@ -1358,6 +1358,15 @@ static int parse_packet(AVFormatContext *s, AVPacket *pkt, int stream_index)
 
         pkt->pts = pkt->dts = AV_NOPTS_VALUE;
         pkt->pos = -1;
+
+        /**
+        ************************************************************************
+        * @author   Michael Verberne (michael.verberne@irdeto.com)
+        * @date     Jul 30, 2015
+        ************************************************************************
+        */
+        out_pkt.hdr_size = pkt->hdr_size;
+
         /* increment read pointer */
         data += len;
         size -= len;
diff --git a/source/libavutil/frame.c b/source/libavutil/frame.c
index d5c7c9f..9ab5313 100644
--- a/source/libavutil/frame.c
+++ b/source/libavutil/frame.c
@@ -294,6 +294,9 @@ static int frame_copy_props(AVFrame *dst, const AVFrame *src, int force_copy)
     dst->palette_has_changed    = src->palette_has_changed;
     dst->sample_rate            = src->sample_rate;
     dst->opaque                 = src->opaque;
+#ifdef IRDETO
+    //dst->irdeto_export          = src->irdeto_export;
+#endif
     dst->pkt_pts                = src->pkt_pts;
     dst->pkt_dts                = src->pkt_dts;
     dst->pkt_pos                = src->pkt_pos;
@@ -368,6 +371,8 @@ FF_DISABLE_DEPRECATION_WARNINGS
 FF_ENABLE_DEPRECATION_WARNINGS
 #endif
 
+    dst->mb_type = src->mb_type;
+
     return 0;
 }
 
@@ -461,6 +466,11 @@ int av_frame_ref(AVFrame *dst, const AVFrame *src)
     memcpy(dst->data,     src->data,     sizeof(src->data));
     memcpy(dst->linesize, src->linesize, sizeof(src->linesize));
 
+#ifdef IRDETO
+    dst->opaque = src->opaque;
+    //dst->irdeto_export = src->irdeto_export;
+#endif
+
     return 0;
 
 fail:
diff --git a/source/libavutil/frame.h b/source/libavutil/frame.h
index 2b5c332..d1921a6 100644
--- a/source/libavutil/frame.h
+++ b/source/libavutil/frame.h
@@ -294,6 +294,11 @@ typedef struct AVFrame {
     int quality;
 
     /**
+     * macroblock type table
+     * mb_type_base + mb_width + 2
+     */
+    uint32_t *mb_type;
+    /**
      * for some private data of the user
      */
     void *opaque;
@@ -385,6 +390,7 @@ typedef struct AVFrame {
 
 /**
  * @defgroup lavu_frame_flags AV_FRAME_FLAGS
+ * @ingroup lavu_frame
  * Flags describing additional frame properties.
  *
  * @{
@@ -501,13 +507,11 @@ typedef struct AVFrame {
      * QP table
      * Not to be accessed directly from outside libavutil
      */
-    attribute_deprecated
     int8_t *qscale_table;
     /**
      * QP store stride
      * Not to be accessed directly from outside libavutil
      */
-    attribute_deprecated
     int qstride;
 
     attribute_deprecated
@@ -523,6 +527,14 @@ typedef struct AVFrame {
      * AVHWFramesContext describing the frame.
      */
     AVBufferRef *hw_frames_ctx;
+
+#ifdef IRDETO
+    /** !mv
+     * For Irdeto specific data
+     */
+    //void *irdeto_export;
+#endif
+
 } AVFrame;
 
 /**
diff --git a/source/libavutil/pixdesc.c b/source/libavutil/pixdesc.c
index 0dffa4d..ae65d1c 100644
--- a/source/libavutil/pixdesc.c
+++ b/source/libavutil/pixdesc.c
@@ -131,6 +131,7 @@ void av_write_image_line(const uint16_t *src,
 FF_DISABLE_DEPRECATION_WARNINGS
 #endif
 static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
+#if 0
     [AV_PIX_FMT_YUV420P] = {
         .name = "yuv420p",
         .nb_components = 3,
@@ -143,6 +144,21 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_PLANAR,
     },
+#else
+    [AV_PIX_FMT_YUV420P] = {
+        .name = "yuv420p",
+        .nb_components = 4,
+        .log2_chroma_w = 1,
+        .log2_chroma_h = 1,
+        .comp = {
+            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
+            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
+            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
+            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec*/
+        },
+        .flags = AV_PIX_FMT_FLAG_PLANAR,
+    },
+#endif
     [AV_PIX_FMT_YUYV422] = {
         .name = "yuyv422",
         .nb_components = 3,
@@ -189,6 +205,8 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_RGB,
     },
+
+#if 0
     [AV_PIX_FMT_YUV422P] = {
         .name = "yuv422p",
         .nb_components = 3,
@@ -201,6 +219,23 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_PLANAR,
     },
+#else
+    [AV_PIX_FMT_YUV422P] = {
+        .name = "yuv422p",
+        .nb_components = 4,
+        .log2_chroma_w = 1,
+        .log2_chroma_h = 0,
+        .comp = {
+            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
+            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
+            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
+            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec*/
+        },
+        .flags = AV_PIX_FMT_FLAG_PLANAR,
+    },
+#endif
+
+#if 0
     [AV_PIX_FMT_YUV444P] = {
         .name = "yuv444p",
         .nb_components = 3,
@@ -213,6 +248,23 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_PLANAR,
     },
+#else
+    [AV_PIX_FMT_YUV444P] = {
+        .name = "yuv444p",
+        .nb_components = 4,
+        .log2_chroma_w = 0,
+        .log2_chroma_h = 0,
+        .comp = {
+            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
+            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
+            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
+            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec*/
+        },
+        .flags = AV_PIX_FMT_FLAG_PLANAR,
+    },
+#endif
+
+#if 0
     [AV_PIX_FMT_YUV410P] = {
         .name = "yuv410p",
         .nb_components = 3,
@@ -225,6 +277,22 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_PLANAR,
     },
+#else
+    [AV_PIX_FMT_YUV410P] = {
+        .name = "yuv410p",
+        .nb_components = 4,
+        .log2_chroma_w = 2,
+        .log2_chroma_h = 2,
+        .comp = {
+            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
+            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
+            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
+            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec */
+        },
+        .flags = AV_PIX_FMT_FLAG_PLANAR,
+    },
+#endif
+#if 0
     [AV_PIX_FMT_YUV411P] = {
         .name = "yuv411p",
         .nb_components = 3,
@@ -237,6 +305,22 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_PLANAR,
     },
+#else
+    [AV_PIX_FMT_YUV411P] = {
+        .name = "yuv411p",
+        .nb_components = 4,
+        .log2_chroma_w = 2,
+        .log2_chroma_h = 0,
+        .comp = {
+            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
+            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
+            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
+            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec */
+        },
+        .flags = AV_PIX_FMT_FLAG_PLANAR,
+    },
+#endif
+#if 0
     [AV_PIX_FMT_YUVJ411P] = {
         .name = "yuvj411p",
         .nb_components = 3,
@@ -249,6 +333,21 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_PLANAR,
     },
+#else
+   [AV_PIX_FMT_YUVJ411P] = {
+        .name = "yuvj411p",
+        .nb_components = 4,
+        .log2_chroma_w = 2,
+        .log2_chroma_h = 0,
+        .comp = {
+            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
+            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
+            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
+            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec */
+        },
+        .flags = AV_PIX_FMT_FLAG_PLANAR,
+    },
+#endif
     [AV_PIX_FMT_GRAY8] = {
         .name = "gray",
         .nb_components = 1,
@@ -290,6 +389,7 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_PAL,
     },
+#if 0
     [AV_PIX_FMT_YUVJ420P] = {
         .name = "yuvj420p",
         .nb_components = 3,
@@ -302,6 +402,22 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_PLANAR,
     },
+#else
+    [AV_PIX_FMT_YUVJ420P] = {
+        .name = "yuvj420p",
+        .nb_components = 4,
+        .log2_chroma_w = 1,
+        .log2_chroma_h = 1,
+        .comp = {
+            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
+            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
+            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
+            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec*/
+        },
+        .flags = AV_PIX_FMT_FLAG_PLANAR,
+    },
+#endif
+#if 0
     [AV_PIX_FMT_YUVJ422P] = {
         .name = "yuvj422p",
         .nb_components = 3,
@@ -314,6 +430,22 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_PLANAR,
     },
+#else
+    [AV_PIX_FMT_YUVJ422P] = {
+        .name = "yuvj422p",
+        .nb_components = 4,
+        .log2_chroma_w = 1,
+        .log2_chroma_h = 0,
+        .comp = {
+            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
+            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
+            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
+            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec */
+        },
+        .flags = AV_PIX_FMT_FLAG_PLANAR,
+    },
+#endif
+#if 0
     [AV_PIX_FMT_YUVJ444P] = {
         .name = "yuvj444p",
         .nb_components = 3,
@@ -326,6 +458,21 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_PLANAR,
     },
+#else
+    [AV_PIX_FMT_YUVJ444P] = {
+        .name = "yuvj444p",
+        .nb_components = 4,
+        .log2_chroma_w = 0,
+        .log2_chroma_h = 0,
+        .comp = {
+            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
+            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
+            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
+            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec */
+        },
+        .flags = AV_PIX_FMT_FLAG_PLANAR,
+    },
+#endif
 #if FF_API_XVMC
     [AV_PIX_FMT_XVMC_MPEG2_MC] = {
         .name = "xvmcmc",
@@ -581,6 +728,7 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .alias = "y16le",
     },
+#if 0
     [AV_PIX_FMT_YUV440P] = {
         .name = "yuv440p",
         .nb_components = 3,
@@ -593,6 +741,22 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_PLANAR,
     },
+#else
+    [AV_PIX_FMT_YUV440P] = {
+        .name = "yuv440p",
+        .nb_components = 4,
+        .log2_chroma_w = 0,
+        .log2_chroma_h = 1,
+        .comp = {
+            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
+            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
+            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
+            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec */
+        },
+        .flags = AV_PIX_FMT_FLAG_PLANAR,
+    },
+#endif
+#if 0
     [AV_PIX_FMT_YUVJ440P] = {
         .name = "yuvj440p",
         .nb_components = 3,
@@ -605,6 +769,21 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_PLANAR,
     },
+#else
+    [AV_PIX_FMT_YUVJ440P] = {
+        .name = "yuvj440p",
+        .nb_components = 4,
+        .log2_chroma_w = 0,
+        .log2_chroma_h = 1,
+        .comp = {
+            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
+            { 1, 1, 0, 0, 8, 0, 7, 1 },        /* U */
+            { 2, 1, 0, 0, 8, 0, 7, 1 },        /* V */
+            { 3, 1, 0, 0, 8, 0, 7, 1 },        /* Y rec */
+        },
+        .flags = AV_PIX_FMT_FLAG_PLANAR,
+    },
+#endif
     [AV_PIX_FMT_YUV440P10LE] = {
         .name = "yuv440p10le",
         .nb_components = 3,
@@ -616,6 +795,7 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
             { 2, 2, 0, 0, 10, 1, 9, 1 },        /* V */
         },
         .flags = AV_PIX_FMT_FLAG_PLANAR,
+
     },
     [AV_PIX_FMT_YUV440P10BE] = {
         .name = "yuv440p10be",
@@ -2271,6 +2451,7 @@ int av_pix_fmt_count_planes(enum AVPixelFormat pix_fmt)
         planes[desc->comp[i].plane] = 1;
     for (i = 0; i < FF_ARRAY_ELEMS(planes); i++)
         ret += planes[i];
+//    fprintf(stderr, "av_pix_fmt_count_planes() %d", ret);
     return ret;
 }
 
diff --git a/source/libavutil/timestamp.h b/source/libavutil/timestamp.h
index f010a7e..02830ae 100644
--- a/source/libavutil/timestamp.h
+++ b/source/libavutil/timestamp.h
@@ -42,8 +42,24 @@
  */
 static inline char *av_ts_make_string(char *buf, int64_t ts)
 {
-    if (ts == AV_NOPTS_VALUE) snprintf(buf, AV_TS_MAX_STRING_SIZE, "NOPTS");
-    else                      snprintf(buf, AV_TS_MAX_STRING_SIZE, "%"PRId64, ts);
+    // if (ts == AV_NOPTS_VALUE) snprintf(buf, AV_TS_MAX_STRING_SIZE, "NOPTS");
+    // else                      snprintf(buf, AV_TS_MAX_STRING_SIZE, "%"PRId64, ts);
+    
+	/**
+	****************************************************************************
+	* @author 	Maksym Koshel (maksym.koshel@irdeto.com)
+	* @brief 	C++11 compatibility fix
+	* @date 	Aug 4, 2015
+	****************************************************************************
+	*/
+	if (ts == AV_NOPTS_VALUE)
+	{
+		snprintf(buf, AV_TS_MAX_STRING_SIZE, "NOPTS");
+	}
+	else
+    {
+	   	snprintf(buf, AV_TS_MAX_STRING_SIZE, "%" PRId64, ts);
+    }
     return buf;
 }
 
